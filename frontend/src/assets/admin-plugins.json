[
  {
    "name": "cockroach-cdc",
    "version": "19.1.0",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/cockroachdb/cockroach-cdc/versions/19.1.0",
    "title": "CockroachDB Change Data Capture",
    "description": "CockroachDB provides ultra-resilient SQL for global business. Its efficient, distributed, row-level change data capture functionality supports Kafka as a sink. (This functionality requires a CockroachDB enterprise license.)",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/cockroachdb/cockroach-cdc/versions/19.1.0/assets/cockroachdb-icon.png",
    "documentation_url": "https://www.cockroachlabs.com/docs/v19.1/change-data-capture.html",
    "source_url": null,
    "support": {
      "provider_name": "Cockroach Labs",
      "summary": "Enterprise support for CockroachDB is available from Cockroach Labs. In addition, community support is available through the CockroachDB forum.",
      "url": "https://www.cockroachlabs.com/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/cockroachdb/cockroach-cdc/versions/19.1.0/assets/cockroach-labs-logo.png"
    },
    "owner": {
      "username": "cockroachdb",
      "type": "Organization",
      "name": "Cockroach Labs",
      "url": "https://www.cockroachlabs.com/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/cockroachdb/cockroach-cdc/versions/19.1.0/assets/cockroach-labs-logo.png"
    },
    "archive": null,
    "docker_image": null,
    "confluent_verified": {
      "level": "standard"
    },
    "features": {
      "supported_encodings": [
        "json",
        "avro"
      ],
      "single_message_transforms": false,
      "confluent_control_center_integration": false,
      "kafka_connect_api": false,
      "delivery_guarantee": [
        "at_least_once"
      ]
    },
    "license": [
      {
        "name": "CockroachDB Community License",
        "url": "https://github.com/cockroachdb/cockroach/blob/master/licenses/CCL.txt",
        "logo": null
      },
      {
        "name": "Apache License, Version 2.0",
        "url": "https://github.com/cockroachdb/cockroach/blob/master/licenses/APL.txt",
        "logo": null
      }
    ],
    "component_types": [
      "source"
    ],
    "release_date": null,
    "tags": [
      "database",
      "change data capture",
      "CDC",
      "SQL"
    ],
    "requirements": [
      "CockroachDB 19.1"
    ],
    "signatures": null,
    "last_modified": 1558138766000
  },
  {
    "name": "vertica-analytics-platform",
    "version": "9.0.0",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/vertica/vertica-analytics-platform/versions/9.0.0",
    "title": "Vertica Analytics Platform",
    "description": "Vertica is the most advanced SQL database analytics portfolio built from the very first line of code to address the most demanding Big Data analytics initiatives.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/vertica/vertica-analytics-platform/versions/9.0.0/assets/Vertica.jpg",
    "documentation_url": "https://my.vertica.com/docs/9.0.x/HTML/",
    "source_url": null,
    "support": null,
    "owner": {
      "username": "vertica",
      "type": "Organization",
      "name": "Vertica",
      "url": "https://my.vertica.com/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/vertica/vertica-analytics-platform/versions/9.0.0/assets/Vertica.jpg"
    },
    "archive": null,
    "docker_image": null,
    "confluent_verified": {
      "level": "standard"
    },
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": null,
      "confluent_control_center_integration": null,
      "kafka_connect_api": null,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Proprietary",
        "url": null,
        "logo": null
      }
    ],
    "component_types": [
      "source",
      "sink"
    ],
    "release_date": null,
    "tags": [
      "Analytics"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1535074643000
  },
  {
    "name": "debezium-connector-mysql",
    "version": "0.9.5",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/debezium/debezium-connector-mysql/versions/0.9.5",
    "title": "Debezium MySQL CDC Connector",
    "description": "Debezium’s MySQL Connector can monitor and record all of the row-level changes in the databases on a <a href=\"https://www.mysql.com/\">MySQL</a> server or <a href=\"https://www.mysql.com/products/cluster/availability.html\">HA MySQL cluster</a>. The first time it connects to a MySQL server/cluster, it reads a consistent snapshot of all of the databases. When that snapshot is complete, the connector continuously reads the changes that were committed to MySQL 5.6 or later and generates corresponding insert, update and delete events. All of the events for each table are recorded in a separate Kafka topic, where they can be easily consumed by applications and services.\n\nAs of Debezium 0.4.0, this connector adds preliminary support for <a href=\"https://aws.amazon.com/rds/mysql/\">Amazon RDS</a> and <a href=\"https://aws.amazon.com/rds/aurora/\">Amazon Aurora (MySQL compatibility)</a>. However, due to limitations of these hosted forms of MySQL, the connector retains locks during an initial consistent snapshot for the duration of the snapshot.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/debezium/debezium-connector-mysql/versions/0.9.5/assets/mysql.png",
    "documentation_url": "http://debezium.io/docs/connectors/mysql/",
    "source_url": "https://github.com/debezium/debezium/",
    "support": {
      "provider_name": "Confluent, Inc.",
      "summary": "Confluent supports Debezium's MySQL Connector version 0.9.3 and later, and using this connector with MySQL 5.6 or later. Find more information <a href=\"https://docs.confluent.io/current/connect/debezium-connect-mysql/index.html\">here</a>. <p>This connector is <a href=\"https://www.confluent.io/subscription/\">supported by Confluent</a> as part of a\n<a href=\"https://www.confluent.io/product/confluent-platform/\">Confluent Platform</a> subscription.",
      "url": "https://docs.confluent.io/current/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/debezium/debezium-connector-mysql/versions/0.9.5/assets/confluent.png"
    },
    "owner": {
      "username": "debezium",
      "type": "Organization",
      "name": "Debezium Community",
      "url": "https://debezium.io",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/debezium/debezium-connector-mysql/versions/0.9.5/assets/mysql.png"
    },
    "archive": {
      "name": "debezium-debezium-connector-mysql-0.9.5.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/debezium/debezium-connector-mysql/versions/0.9.5/debezium-debezium-connector-mysql-0.9.5.zip",
      "mime_type": "application/zip",
      "md5": "9dad4d3259a485f314877bc50a3db9b5",
      "sha1": "2340b01f311504747b60927c574c27a04e5f280c",
      "asc": null
    },
    "docker_image": {
      "namespace": "debezium",
      "name": "debezium/connect",
      "tag": "0.9.5",
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Apache 2.0",
        "url": "https://github.com/debezium/debezium/blob/master/LICENSE.txt",
        "logo": null
      }
    ],
    "component_types": [
      "source"
    ],
    "release_date": null,
    "tags": [
      "change data capture",
      "rdbms",
      "cdc",
      "mysql",
      "dbms",
      "relational",
      "jdbc",
      "amazon rds",
      "amazon aurora",
      "snapshot"
    ],
    "requirements": [
      "MySQL 5.6.x, 5.7.x, or later"
    ],
    "signatures": null,
    "last_modified": 1563842275000
  },
  {
    "name": "debezium-connector-postgresql",
    "version": "0.9.5",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/debezium/debezium-connector-postgresql/versions/0.9.5",
    "title": "Debezium PostgreSQL CDC Connector",
    "description": "Debezium’s PostgreSQL Connector can monitor and record the row-level changes in the schemas of a <a href=\"\">PostgreSQL database</a>. The first time it connects to a PostgreSQL server/cluster, it reads a consistent snapshot of all of the schemas. When that snapshot is complete, the connector continuously streams the changes that were committed to PostgreSQL 9.6 or later and generates corresponding insert, update and delete events. All of the events for each table are recorded in a separate Kafka topic, where they can be easily consumed by applications and services.\nThis connector requires the PostgreSQL server have a logical decoding plugin installed and configured. See the <a href=\"http://debezium.io/docs/connectors/postgresql/\">documentation</a> for details.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/debezium/debezium-connector-postgresql/versions/0.9.5/assets/postgres.png",
    "documentation_url": "http://debezium.io/docs/connectors/postgresql/",
    "source_url": "https://github.com/debezium/debezium/",
    "support": {
      "provider_name": "Confluent, Inc.",
      "summary": "Confluent supports Debezium's PostgreSQL Connector version 0.9.3 and later, and using this connector with PostgreSQL 9.6 or later. Find more information <a href=\"https://docs.confluent.io/current/connect/debezium-connect-postgres/index.html\">here</a>.<p>This connector is <a href=\"https://www.confluent.io/subscription/\">supported by Confluent</a> as part of a\n<a href=\"https://www.confluent.io/product/confluent-platform/\">Confluent Platform</a> subscription.",
      "url": "https://docs.confluent.io/current/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/debezium/debezium-connector-postgresql/versions/0.9.5/assets/confluent.png"
    },
    "owner": {
      "username": "debezium",
      "type": "Organization",
      "name": "Debezium Community",
      "url": "https://debezium.io",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/debezium/debezium-connector-postgresql/versions/0.9.5/assets/postgres.png"
    },
    "archive": {
      "name": "debezium-debezium-connector-postgresql-0.9.5.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/debezium/debezium-connector-postgresql/versions/0.9.5/debezium-debezium-connector-postgresql-0.9.5.zip",
      "mime_type": "application/zip",
      "md5": "75accb42050f3ad76c4af6c94c6a43f6",
      "sha1": "9070336777e5928e099192e855954cd3244a36aa",
      "asc": null
    },
    "docker_image": {
      "namespace": "debezium",
      "name": "debezium/connect",
      "tag": "0.9.5",
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Apache 2.0",
        "url": "https://github.com/debezium/debezium/blob/master/LICENSE.txt",
        "logo": null
      }
    ],
    "component_types": [
      "source"
    ],
    "release_date": null,
    "tags": [
      "change data capture",
      "rdbms",
      "cdc",
      "postgresql",
      "json",
      "dbms",
      "relational",
      "postgres",
      "snapshot"
    ],
    "requirements": [
      "PostgreSQL 9.6 or later"
    ],
    "signatures": null,
    "last_modified": 1563839336000
  },
  {
    "name": "debezium-connector-sqlserver",
    "version": "0.9.5",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/debezium/debezium-connector-sqlserver/versions/0.9.5",
    "title": "Debezium SQL Server CDC Connector",
    "description": "Debezium’s SQL Server Connector can monitor and record the row-level changes in the schemas of a SQL Server 2017 database. This connector was added in Debezium 0.9.0.\n\nThe first time it connects to a SQL Server database/cluster, it reads a consistent snapshot of all of the schemas. When that snapshot is complete, the connector continuously streams the changes that were committed to SQL Server and generates corresponding insert, update and delete events. All of the events for each table are recorded in a separate Kafka topic, where they can be easily consumed by applications and services.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/debezium/debezium-connector-sqlserver/versions/0.9.5/assets/sqlserver.png",
    "documentation_url": "http://debezium.io/docs/connectors/sqlserver/",
    "source_url": "https://github.com/debezium/debezium/",
    "support": {
      "provider_name": "Confluent, Inc.",
      "summary": "Confluent supports Debezium's SQL Server connector version 0.9.3 and later, and using this connector with SQL Server 2016 SP1 or later. SQL Server on Microsoft Azure is currently not supported. Find more information Find more information <a href=\"https://docs.confluent.io/current/connect/debezium-connect-sqlserver/index.html\">here</a>.<p>This connector is <a href=\"https://www.confluent.io/subscription/\">supported by Confluent</a> as part of a\n<a href=\"https://www.confluent.io/product/confluent-platform/\">Confluent Platform</a> subscription.",
      "url": "https://docs.confluent.io/current/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/debezium/debezium-connector-sqlserver/versions/0.9.5/assets/confluent.png"
    },
    "owner": {
      "username": "debezium",
      "type": "Organization",
      "name": "Debezium Community",
      "url": "https://debezium.io",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/debezium/debezium-connector-sqlserver/versions/0.9.5/assets/sqlserver.png"
    },
    "archive": {
      "name": "debezium-debezium-connector-sqlserver-0.9.5.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/debezium/debezium-connector-sqlserver/versions/0.9.5/debezium-debezium-connector-sqlserver-0.9.5.zip",
      "mime_type": "application/zip",
      "md5": "d9f805e0feb72c574d1af0e70835c8b2",
      "sha1": "daf696b99750665c3fb707355e49e806db605803",
      "asc": null
    },
    "docker_image": {
      "namespace": "debezium",
      "name": "debezium/connect",
      "tag": "0.9.5",
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Apache 2.0",
        "url": "https://github.com/debezium/debezium/blob/master/LICENSE.txt",
        "logo": null
      }
    ],
    "component_types": [
      "source"
    ],
    "release_date": null,
    "tags": [
      "server",
      "change data capture",
      "rdbms",
      "cdc",
      "relational",
      "jdbc",
      "microsoft",
      "snapshot",
      "sql"
    ],
    "requirements": [
      "SQL Server 2017"
    ],
    "signatures": null,
    "last_modified": 1563843763000
  },
  {
    "name": "debezium-connector-mongodb",
    "version": "0.9.5",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/debezium/debezium-connector-mongodb/versions/0.9.5",
    "title": "Debezium MongoDB CDC Connector",
    "description": "Debezium’s MongoDB Connector can monitor a <a href=\"https://docs.mongodb.com/manual/tutorial/deploy-replica-set/\">MongoDB replica set</a> or a <a href=\"https://docs.mongodb.com/manual/core/sharded-cluster-components/\">MongoDB sharded cluster</a> for document changes in databases and collections, recording those changes as events in Kafka topics. The connector automatically handles the addition or removal of shards in a sharded cluster, changes in membership of each replica set, elections within each replica set, and awaiting the resolution of communications problems.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/debezium/debezium-connector-mongodb/versions/0.9.5/assets/mongodb-leaf.png",
    "documentation_url": "http://debezium.io/docs/connectors/mongodb/",
    "source_url": "https://github.com/debezium/debezium/",
    "support": {
      "provider_name": "Confluent, Inc.",
      "summary": "Confluent supports Debezium's MongoDB CDC Connector version 0.9.3 and later, and using this connector with MongoDB version 3.4 or later. Find more information <a href=\"https://docs.confluent.io/current/connect/debezium-connect-mongodb/index.html\">here</a>.<p>This connector is <a href=\"https://www.confluent.io/subscription/\">supported by Confluent</a> as part of a\n<a href=\"https://www.confluent.io/product/confluent-platform/\">Confluent Platform</a> subscription.",
      "url": "https://docs.confluent.io/current/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/debezium/debezium-connector-mongodb/versions/0.9.5/assets/confluent.png"
    },
    "owner": {
      "username": "debezium",
      "type": "Organization",
      "name": "Debezium Community",
      "url": "https://debezium.io",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/debezium/debezium-connector-mongodb/versions/0.9.5/assets/mongodb-leaf.png"
    },
    "archive": {
      "name": "debezium-debezium-connector-mongodb-0.9.5.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/debezium/debezium-connector-mongodb/versions/0.9.5/debezium-debezium-connector-mongodb-0.9.5.zip",
      "mime_type": "application/zip",
      "md5": "b2841ae7c53a403ae244ce64902b36d1",
      "sha1": "64538a56cc8c11fb07d520ed4f13c5655a004b56",
      "asc": null
    },
    "docker_image": {
      "namespace": "debezium",
      "name": "debezium/connect",
      "tag": "0.9.5",
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Apache 2.0",
        "url": "https://github.com/debezium/debezium/blob/master/LICENSE.txt",
        "logo": null
      }
    ],
    "component_types": [
      "source"
    ],
    "release_date": null,
    "tags": [
      "change data capture",
      "cdc",
      "document database",
      "json",
      "mongodb",
      "snapshot"
    ],
    "requirements": [
      "MongoDB 3.6.x and later"
    ],
    "signatures": null,
    "last_modified": 1563836767000
  },
  {
    "name": "kafka-connect-data-diode",
    "version": "1.1.0",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-data-diode/versions/1.1.0",
    "title": "Kafka Connect Data Diode",
    "description": "A Kafka connect pair of connectors to replicate topics \nover a unidirectional network using UDP packets.\nThis is meant to be used in security conscious networks where TCP/IP cannot be used.",
    "logo": null,
    "documentation_url": "https://docs.confluent.io/current/connect/kafka-connect-data-diode/",
    "source_url": null,
    "support": {
      "provider_name": null,
      "summary": "This connector is <a href=\"https://www.confluent.io/subscription/\">supported by Confluent</a> as part of a\n<a href=\"https://www.confluent.io/product/confluent-platform/\">Confluent Platform</a> subscription.",
      "url": null,
      "logo": null
    },
    "owner": {
      "username": "confluentinc",
      "type": null,
      "name": "Confluent, Inc.",
      "url": null,
      "logo": null
    },
    "archive": {
      "name": "confluentinc-kafka-connect-data-diode-1.1.0.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-data-diode/versions/1.1.0/confluentinc-kafka-connect-data-diode-1.1.0.zip",
      "mime_type": "application/zip",
      "md5": "7706409ad9c55b720dd8efafaa3ccec2",
      "sha1": "3a58551c0aebe7dbeedc823d2c56c58c3b82f428",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Software Evaluation License",
        "url": "https://www.confluent.io/software-evaluation-license",
        "logo": null
      }
    ],
    "component_types": [
      "source",
      "sink"
    ],
    "release_date": "2019-09-06",
    "tags": [
      "UDP",
      "Unidirectional",
      "Replicator"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1567753366000
  },
  {
    "name": "kafka-connect-activemq",
    "version": "5.3.0",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-activemq/versions/5.3.0",
    "title": "Kafka Connect ActiveMQ Source",
    "description": "The ActiveMQ Source Connector is used to read messages from an ActiveMQ cluster and write them to a Kafka topic.\n\nIt is included in <a href=\"https://www.confluent.io/product/confluent-enterprise/\">Confluent Enterprise Platform</a>, or can be downloaded and installed separately. It can be used for free for 30 days, but after that does require an Enterprise license. <a href=\"https://www.confluent.io/contact/\">Contact Confluent</a> for more details.",
    "logo": null,
    "documentation_url": "https://docs.confluent.io/5.3.0/connect/connect-jms/kafka-connect-activemq/docs/index.html",
    "source_url": null,
    "support": {
      "provider_name": "Confluent, Inc.",
      "summary": "This connector is <a href=\"http://confluent.io/subscription/\">fully supported by\nConfluent</a> as part of a\n<a href=\"https://www.confluent.io/product/confluent-enterprise/\">Confluent Enterprise Platform</a> subscription.",
      "url": "http://confluent.io/subscription/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-activemq/versions/5.3.0/assets/confluent.png"
    },
    "owner": {
      "username": "confluentinc",
      "type": "Organization",
      "name": "Confluent, Inc.",
      "url": "http://confluent.io",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-activemq/versions/5.3.0/assets/confluent.png"
    },
    "archive": {
      "name": "confluentinc-kafka-connect-activemq-5.3.0.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-activemq/versions/5.3.0/confluentinc-kafka-connect-activemq-5.3.0.zip",
      "mime_type": "application/zip",
      "md5": "55146cf621c57d78dc90985ad4fae29a",
      "sha1": "c9da436cda0c1fd55cb9189ca4594c227458bd14",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Software Evaluation License",
        "url": "https://www.confluent.io/software-evaluation-license",
        "logo": null
      }
    ],
    "component_types": [
      "source"
    ],
    "release_date": "2019-07-22",
    "tags": [
      "JMS",
      "AMQ",
      "Message Broker",
      "ActiveMQ"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1563827101000
  },
  {
    "name": "kafka-connect-omnisci",
    "version": "1.0.2",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-omnisci/versions/1.0.2",
    "title": "Kafka Connect OmniSci Sink",
    "description": "A Kafka Connect plugin for OmniSci Sink Connector",
    "logo": null,
    "documentation_url": "https://docs.confluent.io/current/connect/kafka-connect-omnisci/",
    "source_url": null,
    "support": {
      "provider_name": null,
      "summary": "This connector is <a href=\"https://www.confluent.io/subscription/\">supported by Confluent</a> as part of a\n<a href=\"https://www.confluent.io/product/confluent-platform/\">Confluent Platform</a> subscription.",
      "url": null,
      "logo": null
    },
    "owner": {
      "username": "confluentinc",
      "type": null,
      "name": "Confluent, Inc.",
      "url": null,
      "logo": null
    },
    "archive": {
      "name": "confluentinc-kafka-connect-omnisci-1.0.2.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-omnisci/versions/1.0.2/confluentinc-kafka-connect-omnisci-1.0.2.zip",
      "mime_type": "application/zip",
      "md5": "c004fb0bc81f18f7469d7d52d26ba0b7",
      "sha1": "8945f2d8e8153038a6f4069dadf219247002ad51",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Software Evaluation License",
        "url": "https://www.confluent.io/software-evaluation-license",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": "2019-08-20",
    "tags": [
      "OmniSci Sink Connector"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1566336244000
  },
  {
    "name": "kafka-connect-syslog",
    "version": "1.2.6",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-syslog/versions/1.2.6",
    "title": "Kafka Connect Syslog",
    "description": "The Confluent Syslog Connector is used to move messages from Network devices into Kafka.",
    "logo": null,
    "documentation_url": "https://docs.confluent.io/current/connect/kafka-connect-syslog/index.html",
    "source_url": null,
    "support": {
      "provider_name": null,
      "summary": "This connector is <a href=\"https://www.confluent.io/subscription/\">supported by Confluent</a> as part of a\n<a href=\"https://www.confluent.io/product/confluent-platform/\">Confluent Enterprise Platform</a> subscription.",
      "url": null,
      "logo": null
    },
    "owner": {
      "username": "confluentinc",
      "type": null,
      "name": "Confluent, Inc.",
      "url": null,
      "logo": null
    },
    "archive": {
      "name": "confluentinc-kafka-connect-syslog-1.2.6.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-syslog/versions/1.2.6/confluentinc-kafka-connect-syslog-1.2.6.zip",
      "mime_type": "application/zip",
      "md5": "2b450fe2e7953d1bd16bc9eb9187668f",
      "sha1": "2d2e945f3ffa5f66b5a2ca377a7e45417095f0ff",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Software Evaluation License",
        "url": "https://www.confluent.io/software-evaluation-license",
        "logo": null
      }
    ],
    "component_types": [
      "source"
    ],
    "release_date": "2019-05-21",
    "tags": [
      "Logging",
      "Syslog",
      "Network"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1558464227000
  },
  {
    "name": "kafka-connect-maprdb",
    "version": "1.0.0-preview",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-maprdb/versions/1.0.0-preview",
    "title": "Kafka Connect MapRDB",
    "description": "A Kafka Connect plugin for writing data from Kafka to MapR DB.",
    "logo": null,
    "documentation_url": "https://github.com/jcustenborder/kafka-connect-maprdb",
    "source_url": null,
    "support": {
      "provider_name": null,
      "summary": "Confluent is introducing this preview connector to gain early feedback from developers. It should only be used for evaluation and non-production testing purposes or to provide feedback to Confluent and is subject to the <a href=\"https://www.confluent.io/confluent-software-evaluation-license/\">Confluent Software Evaluation License</a>. Confluent will provide support for this connector for evaluation and non-production testing purposes.\n\nComments, questions and suggestions related to preview features are encouraged. Confluent customers may submit questions and suggestions, and file support tickets via the <a href=\"https://support.confluent.io/\">Confluent Support Portal</a>.",
      "url": null,
      "logo": null
    },
    "owner": {
      "username": "confluentinc",
      "type": null,
      "name": "Confluent, Inc.",
      "url": null,
      "logo": null
    },
    "archive": {
      "name": "confluentinc-kafka-connect-maprdb-1.0.0-preview.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-maprdb/versions/1.0.0-preview/confluentinc-kafka-connect-maprdb-1.0.0-preview.zip",
      "mime_type": "application/zip",
      "md5": "9802525e8d62179534324178fdfbd020",
      "sha1": "91364a5e4bc7ddb8e53d43d39c75d984caa80710",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Software Evaluation License",
        "url": "https://www.confluent.io/software-evaluation-license",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": "2018-10-18",
    "tags": [
      "MapR",
      "MapRDB"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1554506878000
  },
  {
    "name": "kafka-connect-jdbc",
    "version": "5.3.0",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-jdbc/versions/5.3.0",
    "title": "Kafka Connect JDBC",
    "description": "The JDBC source and sink connectors allow you to exchange data between relational databases and Kafka.\n\nThe JDBC source connector allows you to import data from any relational database with a JDBC driver into Kafka topics. By using JDBC, this connector can support a wide variety of databases without requiring custom code for each one.\n\nData is loaded by periodically executing a SQL query and creating an output record for each row in the result set. By default, all tables in a database are copied, each to its own output topic. The database is monitored for new or deleted tables and adapts automatically. When copying data from a table, the connector can load only new or modified rows by specifying which columns should be used to detect new or modified data.\n\nThe JDBC sink connector allows you to export data from Kafka topics to any relational database with a JDBC driver. By using JDBC, this connector can support a wide variety of databases without requiring a dedicated connector for each one. The connector polls data from Kafka to write to the database based on the topics subscription. It is possible to achieve idempotent writes with upserts. Auto-creation of tables, and limited auto-evolution is also supported.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-jdbc/versions/5.3.0/assets/jdbc.jpg",
    "documentation_url": "https://docs.confluent.io/5.3.0/connect/connect-jdbc/docs/index.html",
    "source_url": "https://github.com/confluentinc/kafka-connect-jdbc",
    "support": {
      "provider_name": "Confluent, Inc.",
      "summary": "Confluent supports the JDBC sink and source connectors alongside community members as part of its Confluent Platform offering.",
      "url": "https://docs.confluent.io/current/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-jdbc/versions/5.3.0/assets/confluent.png"
    },
    "owner": {
      "username": "confluentinc",
      "type": "Organization",
      "name": "Confluent, Inc.",
      "url": "https://confluent.io/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-jdbc/versions/5.3.0/assets/confluent.png"
    },
    "archive": {
      "name": "confluentinc-kafka-connect-jdbc-5.3.0.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-jdbc/versions/5.3.0/confluentinc-kafka-connect-jdbc-5.3.0.zip",
      "mime_type": "application/zip",
      "md5": "f977061885d3052308cb964002328a19",
      "sha1": "48e6bf0cf64d02be0456431589ab77796e625784",
      "asc": null
    },
    "docker_image": {
      "namespace": "confluentinc",
      "name": "cp-kafka-connect",
      "tag": "5.3.0",
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Community License",
        "url": "http://www.confluent.io/confluent-community-license",
        "logo": null
      }
    ],
    "component_types": [
      "source",
      "sink"
    ],
    "release_date": "2019-07-19",
    "tags": [
      "rdbms",
      "oracle",
      "sybase",
      "vertica",
      "sqlite",
      "jdbc",
      "dbms",
      "sql server",
      "sql",
      "database",
      "postgresql",
      "db2",
      "derby",
      "mysql",
      "sap hana"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1563568886000
  },
  {
    "name": "kafka-connect-aws-lambda",
    "version": "1.0.0-preview",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-aws-lambda/versions/1.0.0-preview",
    "title": "Kafka Connect AWS Lambda",
    "description": "A Kafka Connect plugin for AWS LAMBDA",
    "logo": null,
    "documentation_url": "https://docs.confluent.io/current/connect/kafka-connect-aws-lambda/",
    "source_url": null,
    "support": {
      "provider_name": null,
      "summary": "Confluent is introducing this preview connector to\ngain early feedback from developers. It should only be used for\nevaluation and non-production testing purposes or to provide\nfeedback to Confluent and is subject to the\n<a href=\"https://www.confluent.io/confluent-software-evaluation-license/\">Confluent Software Evaluation License.</a>\nConfluent will provide support for this connector for evaluation and non-production testing purposes.\n\nComments, questions and suggestions related to preview features\nare encouraged. Confluent customers may submit questions and suggestions, and file support tickets via the\n<a href=\"https://support.confluent.io/\">Confluent Support Portal.</a>",
      "url": null,
      "logo": null
    },
    "owner": {
      "username": "confluentinc",
      "type": null,
      "name": "Confluent, Inc.",
      "url": null,
      "logo": null
    },
    "archive": {
      "name": "confluentinc-kafka-connect-aws-lambda-1.0.0-preview.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-aws-lambda/versions/1.0.0-preview/confluentinc-kafka-connect-aws-lambda-1.0.0-preview.zip",
      "mime_type": "application/zip",
      "md5": "dc32e9073157e52dfe2ed6d91702cccd",
      "sha1": "9cac78056e62b896c21eb27ed4d3159d8ce00872",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Software Evaluation License",
        "url": "https://www.confluent.io/software-evaluation-license",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": "2019-08-27",
    "tags": [
      "AWS",
      "LAMBDA"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1566923285000
  },
  {
    "name": "kafka-connect-salesforce",
    "version": "1.2.2",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-salesforce/versions/1.2.2",
    "title": "Kafka Connect Salesforce",
    "description": "The Salesforce Connector integrates <a href=\"https://salesforce.com\">Salesforce.com</a> with Apache Kafka and includes two sink connectors and two source connectors.\n\n<p>The `SalesforcePushTopicSourceConnector` captures changes from Salesforce.com by subscribing to\n<a href=\"https://developer.salesforce.com/docs/atlas.en-us.api_streaming.meta/api_streaming/pushtopic_events_intro.htm\">Salesforce Streaming API PushTopics</a>\nand writes the Salesforce Objects (SObjects) create, update, delete, and undelete events to Apache Kafka.\nThis connector will use an existing named PushTopic if one exists, or it will create a PushTopic with the specified name and type of SObject.\n\n<p>The `SalesforcePlatformEventSourceConnector` subscribes to user defined <a href=\"https://developer.salesforce.com/docs/atlas.en-us.platform_events.meta/platform_events/platform_events_intro_emp.htm\">Salesforce Enterprise Messaging Platform Events</a> and writes them to Kafka.\nYou must first define the Platform Event in Salesforce before starting this connector.\n\n<p>The `SalesforceSObjectSinkConnector` may be used to synchronize changes from one Salesforce organization to another\norganization in tandem with the PushTopic source connector. The sink connector is designed to read Apache Kafka topics\nproduced from the Salesforce PushTopic Source connector and send the create, update, upsert,  or delete\noperations into the target organization.\n\n<p>The `SalesforcePushTopicSinkConnector` can consume Salesforce Platform Events from Apache Kafka topics and publish them to Salesforce.\nSimilar to the SObject sink connector, the Platform Events sink connector expects Apache Kafka records to have the same format\nas messages written by the Salesforce Platform Events source connector. Additionally, this connector expects Platform events to be defined within\nSalesforce before they can be published.",
    "logo": null,
    "documentation_url": "https://docs.confluent.io/current/connect/kafka-connect-salesforce/",
    "source_url": null,
    "support": {
      "provider_name": null,
      "summary": "This connector is <a href=\"https://www.confluent.io/subscription/\">supported by Confluent</a> as part of a\n<a href=\"https://www.confluent.io/product/confluent-platform/\">Confluent Platform</a> subscription.",
      "url": null,
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-salesforce/versions/1.2.2/assets/confluent.png"
    },
    "owner": {
      "username": "confluentinc",
      "type": "Organization",
      "name": "Confluent, Inc.",
      "url": "https://confluent.io/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-salesforce/versions/1.2.2/assets/confluent.png"
    },
    "archive": {
      "name": "confluentinc-kafka-connect-salesforce-1.2.2.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-salesforce/versions/1.2.2/confluentinc-kafka-connect-salesforce-1.2.2.zip",
      "mime_type": "application/zip",
      "md5": "890d2b1cea2fd416882397ad2ebff041",
      "sha1": "7796407b0bda1374441bdf959eb5b224f96a497b",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Software Evaluation License",
        "url": "https://www.confluent.io/software-evaluation-license",
        "logo": null
      }
    ],
    "component_types": [
      "source",
      "sink"
    ],
    "release_date": "2019-08-26",
    "tags": [
      "SFDC",
      "Streaming API",
      "SObjects",
      "Platform Events",
      "Salesforce"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1566852620000
  },
  {
    "name": "kafka-connect-activemq-sink",
    "version": "1.1.0-preview",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-activemq-sink/versions/1.1.0-preview",
    "title": "Kafka Connect ActiveMQ Sink",
    "description": "The Kafka Connect ActiveMQ Sink Connector integrates Kafka with Apache ActiveMQ.\nThe connector consumes records from Kafka topic(s) and converts each record value to either a JMS <pre>TextMessage</pre> or\n<pre>BytesMessage</pre> before producing the JMS Message to ActiveMQ.\n<p>Prerequisites include:\n<ol>\n<li>Kafka Broker: Confluent Platform 3.3.0 or above, or Kafka 0.11.0 or above</li>\n<li>Kafka Connect: Confluent Platform 4.1.0 or above, or Kafka 1.1.0 or above (requires header support in Connect)</li>\n<li>Java 1.8</li>\n</ol>",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-activemq-sink/versions/1.1.0-preview/assets/activemq.png",
    "documentation_url": "https://docs.confluent.io/current/connect/kafka-connect-activemq/sink",
    "source_url": null,
    "support": {
      "provider_name": "Confluent, Inc.",
      "summary": "Confluent is introducing this preview connector to\ngain early feedback from developers. It should only be used for\nevaluation and non-production testing purposes or to provide\nfeedback to Confluent and is subject to the\n<a href=\"https://www.confluent.io/confluent-software-evaluation-license/\">Confluent\nSoftware Evaluation License.</a>\nConfluent will provide support for this connector for evaluation and non-production\ntesting purposes.\nComments, questions and suggestions related to preview features\nare encouraged. Confluent customers may submit questions and suggestions, and file\nsupport tickets via the\n<a href=\"https://support.confluent.io/\">Confluent Support Portal.</a>",
      "url": "http://confluent.io/subscription/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-activemq-sink/versions/1.1.0-preview/assets/confluent.png"
    },
    "owner": {
      "username": "confluentinc",
      "type": "Organization",
      "name": "Confluent, Inc.",
      "url": "https://confluent.io/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-activemq-sink/versions/1.1.0-preview/assets/confluent.png"
    },
    "archive": {
      "name": "confluentinc-kafka-connect-activemq-sink-1.1.0-preview.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-activemq-sink/versions/1.1.0-preview/confluentinc-kafka-connect-activemq-sink-1.1.0-preview.zip",
      "mime_type": "application/zip",
      "md5": "09eec6d09bda7a9d46b837729fa007a0",
      "sha1": "731091f3c4a266813a0306ae9257fbf05e4d8ad3",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Software Evaluation License",
        "url": "https://www.confluent.io/software-evaluation-license",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": "2019-08-20",
    "tags": [
      "Apache ActiveMQ",
      "JMS",
      "Java Message Service",
      "Message Broker",
      "ActiveMQ"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1566342699000
  },
  {
    "name": "kafka-connect-solace-sink",
    "version": "1.1.0-preview",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-solace-sink/versions/1.1.0-preview",
    "title": "Kafka Connect Solace Sink Connector",
    "description": "The Kafka Connect Solace Sink Connector integrates Kafka with Solace.\nThe connector consumes records from Kafka topic(s) and converts each record value to either a JMS <pre>TextMessage</pre> or\n<pre>BytesMessage</pre> before producing the JMS Message to Solace.\n<p>Prerequisites include:\n<ol>\n<li>Kafka Broker: Confluent Platform 3.3.0 or above, or Kafka 0.11.0 or above</li>\n<li>Kafka Connect: Confluent Platform 4.1.0 or above, or Kafka 1.1.0 or above (requires header support in Connect)</li>\n<li>Solace cluster with JMS 1.1 support</li>\n<li>com.solacesystems:sol-jms Client Library</li>\n<li>Java 1.8</li>\n</ol>",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-solace-sink/versions/1.1.0-preview/assets/solace.png",
    "documentation_url": "https://docs.confluent.io/current/connect/kafka-connect-solace/sink",
    "source_url": null,
    "support": {
      "provider_name": "Confluent, Inc.",
      "summary": "Confluent is introducing this preview connector to\ngain early feedback from developers. It should only be used for\nevaluation and non-production testing purposes or to provide\nfeedback to Confluent and is subject to the\n<a href=\"https://www.confluent.io/confluent-software-evaluation-license/\">Confluent\nSoftware Evaluation License.</a>\nConfluent will provide support for this connector for evaluation and non-production\ntesting purposes.\nComments, questions and suggestions related to preview features\nare encouraged. Confluent customers may submit questions and suggestions, and file\nsupport tickets via the\n<a href=\"https://support.confluent.io/\">Confluent Support Portal.</a>",
      "url": "http://confluent.io/subscription/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-solace-sink/versions/1.1.0-preview/assets/confluent.png"
    },
    "owner": {
      "username": "confluentinc",
      "type": "Organization",
      "name": "Confluent, Inc.",
      "url": "https://confluent.io/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-solace-sink/versions/1.1.0-preview/assets/confluent.png"
    },
    "archive": {
      "name": "confluentinc-kafka-connect-solace-sink-1.1.0-preview.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-solace-sink/versions/1.1.0-preview/confluentinc-kafka-connect-solace-sink-1.1.0-preview.zip",
      "mime_type": "application/zip",
      "md5": "1cb0e832b9aba87759c252ea7edc6ef6",
      "sha1": "848d0c3cfc50afe03474abd521916538446c788e",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Software Evaluation License",
        "url": "https://www.confluent.io/software-evaluation-license",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": "2019-08-20",
    "tags": [
      "JMS",
      "Java Message Service",
      "Solace",
      "Message Broker",
      "Solace PubSub"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1566342707000
  },
  {
    "name": "kafka-connect-azure-blob-storage",
    "version": "1.1.1",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-azure-blob-storage/versions/1.1.1",
    "title": "Kafka Connect Azure Blob Storage Sink Connector",
    "description": "The Azure Blob Storage Sink Connector integrates <a href=\"https://azure.microsoft.com/en-us/services/storage/blobs/\">Azure Blob Storage</a> with Apache Kafka.\nThe connector can export data from Apache Kafka® topics to Azure Blob Storage objects in either Avro or JSON formats.\nDepending on your environment, the Azure Blob Storage connector can export data by guaranteeing exactly-once delivery\nsemantics to consumers of the Azure Blob Storage objects it produces.\n\n<p>The Azure Blob Storage sink connector periodically polls data from Kafka and in turn uploads it to Azure Blob Storage.\nA partitioner is used to split the data of every Kafka partition into chunks.\nEach chunk of data is represented as an Azure Blob Storage object. The key name encodes the topic, Kafka partition, and\nstart offset of this data chunk. If no partitioner is specified in the configuration, a default partitioner is used that\npreserves Kafka partitioning. The size of each data chunk is determined by the number of records written to Azure Blob Storage and by schema compatibility.",
    "logo": null,
    "documentation_url": "https://docs.confluent.io/current/connect/kafka-connect-azure-blob-storage/",
    "source_url": null,
    "support": {
      "provider_name": null,
      "summary": "This connector is <a href=\"https://www.confluent.io/subscription/\">supported by Confluent</a> as part of a\n<a href=\"https://www.confluent.io/product/confluent-platform/\">Confluent Platform</a> subscription.",
      "url": null,
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-azure-blob-storage/versions/1.1.1/assets/confluent.png"
    },
    "owner": {
      "username": "confluentinc",
      "type": "Organization",
      "name": "Confluent, Inc.",
      "url": "https://confluent.io/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-azure-blob-storage/versions/1.1.1/assets/confluent.png"
    },
    "archive": {
      "name": "confluentinc-kafka-connect-azure-blob-storage-1.1.1.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-azure-blob-storage/versions/1.1.1/confluentinc-kafka-connect-azure-blob-storage-1.1.1.zip",
      "mime_type": "application/zip",
      "md5": "a352cff359b5df95fd2851a11f0c7b68",
      "sha1": "b3cc8bbf556df2e5224bb813d9d41464ad8a6133",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Software Evaluation License",
        "url": "https://www.confluent.io/software-evaluation-license",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": "2019-08-20",
    "tags": [
      "object storage",
      "blob storage",
      "exactly once",
      "azure"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1566335947000
  },
  {
    "name": "kafka-connect-replicator",
    "version": "5.3.0",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-replicator/versions/5.3.0",
    "title": "Confluent Kafka Replicator",
    "description": "Replicator allows you to easily and reliably replicate topics from one Kafka cluster to another.\nIt continuously copies the messages in multiple topics, when necessary creating the topics in the destination cluster using the same topic configuration in the source cluster.\nThis includes preserving the number of partitions, the replication factor, and any configuration overrides specified for individual topics.\n\nReplicator is included in <a href=\"https://www.confluent.io/product/confluent-enterprise/\">Confluent Enterprise Platform</a>, or can be downloaded\nand installed separately. It can be used for free for 30 days, but after that does require an Enterprise license. <a href=\"https://www.confluent.io/contact/\">Contact Confluent</a>\nfor more details.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-replicator/versions/5.3.0/assets/apache-kafka.png",
    "documentation_url": "https://docs.confluent.io/5.3.0/connect/connect-replicator/docs/index.html",
    "source_url": null,
    "support": {
      "provider_name": "Confluent, Inc.",
      "summary": "This connector is <a href=\"http://confluent.io/subscription/\">fully supported by\nConfluent</a> as part of a\n<a href=\"https://www.confluent.io/product/confluent-enterprise/\">Confluent Enterprise Platform</a> subscription.",
      "url": "http://confluent.io/subscription/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-replicator/versions/5.3.0/assets/confluent.png"
    },
    "owner": {
      "username": "confluentinc",
      "type": "Organization",
      "name": "Confluent, Inc.",
      "url": "http://confluent.io",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-replicator/versions/5.3.0/assets/confluent.png"
    },
    "archive": {
      "name": "confluentinc-kafka-connect-replicator-5.3.0.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-replicator/versions/5.3.0/confluentinc-kafka-connect-replicator-5.3.0.zip",
      "mime_type": "application/zip",
      "md5": "5ee055ec353a815433ad38dcaf972022",
      "sha1": "acafc7252f3e1f87242fbfec41bb0576dbd928cc",
      "asc": null
    },
    "docker_image": {
      "namespace": "confluentinc",
      "name": "cp-enterprise-replicator",
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Software Evaluation License",
        "url": "https://www.confluent.io/software-evaluation-license",
        "logo": null
      }
    ],
    "component_types": [
      "source"
    ],
    "release_date": "2019-07-19",
    "tags": [
      "Aggregation",
      "Multi-DC",
      "Active",
      "Passive",
      "Kafka",
      "Cluster",
      "Replication",
      "Multiple data center"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1563568866000
  },
  {
    "name": "kafka-connect-tibco-source",
    "version": "1.0.0-preview",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-tibco-source/versions/1.0.0-preview",
    "title": "Kafka Connect TIBCO Source",
    "description": "The Kafka Connect TIBCO Source Connector integrates Kafka with TIBCO EMS.\nThe connector consumes records from TIBCO EMS queues or topics produces them to a Kafka topic.\n<p>Prerequisites include:\n<ol>\n<li>Kafka Broker: Confluent Platform 3.3.0 or above, or Kafka 0.11.0 or above</li>\n<li>Kafka Connect: Confluent Platform 4.1.0 or above, or Kafka 1.1.0 or above (requires header support in Connect)</li>\n<li>TIBCO JMS Client Library</li>\n<li>Java 1.8</li>\n</ol>",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-tibco-source/versions/1.0.0-preview/assets/tibco.png",
    "documentation_url": "https://docs.confluent.io/current/connect/kafka-connect-tibco/source",
    "source_url": null,
    "support": {
      "provider_name": "Confluent, Inc.",
      "summary": "Confluent is introducing this preview connector to\ngain early feedback from developers. It should only be used for\nevaluation and non-production testing purposes or to provide\nfeedback to Confluent and is subject to the\n<a href=\"https://www.confluent.io/confluent-software-evaluation-license/\">Confluent\nSoftware Evaluation License.</a>\nConfluent will provide support for this connector for evaluation and non-production\ntesting purposes.\nComments, questions and suggestions related to preview features\nare encouraged. Confluent customers may submit questions and suggestions, and file\nsupport tickets via the\n<a href=\"https://support.confluent.io/\">Confluent Support Portal.</a>",
      "url": "http://confluent.io/subscription/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-tibco-source/versions/1.0.0-preview/assets/confluent.png"
    },
    "owner": {
      "username": "confluentinc",
      "type": "Organization",
      "name": "Confluent, Inc.",
      "url": "https://confluent.io/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-tibco-source/versions/1.0.0-preview/assets/confluent.png"
    },
    "archive": {
      "name": "confluentinc-kafka-connect-tibco-source-1.0.0-preview.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-tibco-source/versions/1.0.0-preview/confluentinc-kafka-connect-tibco-source-1.0.0-preview.zip",
      "mime_type": "application/zip",
      "md5": "4bd22c81bc48de241010dad01de1c481",
      "sha1": "a6ec447ac59543a1a3e2bf4b64d013669a250ee9",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Software Evaluation License",
        "url": "https://www.confluent.io/software-evaluation-license",
        "logo": null
      }
    ],
    "component_types": [
      "source"
    ],
    "release_date": "2019-08-20",
    "tags": [
      "JMS",
      "Java Message Service",
      "TIBCO EMS",
      "Message Broker",
      "TIBCO"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1566342595000
  },
  {
    "name": "kafka-connect-elasticsearch",
    "version": "5.3.0",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-elasticsearch/versions/5.3.0",
    "title": "Kafka Connect Elasticsearch",
    "description": "The Elasticsearch connector allows moving data from Kafka to Elasticsearch. It writes data from a topic in Kafka to an index in Elasticsearch and all data for a topic have the same type.\n\nElasticsearch is often used for text queries, analytics and as an key-value store (use cases). The connector covers both the analytics and key-value store use cases. For the analytics use case, each message is in Kafka is treated as an event and the connector uses topic+partition+offset as a unique identifier for events, which then converted to unique documents in Elasticsearch. For the key-value store use case, it supports using keys from Kafka messages as document ids in Elasticsearch and provides configurations ensuring that updates to a key are written to Elasticsearch in order. For both use cases, Elasticsearch’s idempotent write semantics guarantees exactly once delivery.\n\nMapping is the process of defining how a document, and the fields it contains, are stored and indexed. Users can explicitly define mappings for types in indices. When a mapping is not explicitly defined, Elasticsearch can determine field names and types from data, however, some types such as timestamp and decimal, may not be correctly inferred. To ensure that the types are correctly inferred, the connector provides a feature to infer a mapping from the schemas of Kafka messages.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-elasticsearch/versions/5.3.0/assets/elasticsearch.jpg",
    "documentation_url": "https://docs.confluent.io/5.3.0/connect/connect-elasticsearch/docs/index.html",
    "source_url": "https://github.com/confluentinc/kafka-connect-elasticsearch",
    "support": {
      "provider_name": "Confluent, Inc.",
      "summary": "Confluent supports the Elasticsearch sink connector alongside community members as part of its Confluent Platform offering.",
      "url": "https://docs.confluent.io/current/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-elasticsearch/versions/5.3.0/assets/confluent.png"
    },
    "owner": {
      "username": "confluentinc",
      "type": "Organization",
      "name": "Confluent, Inc.",
      "url": "https://confluent.io/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-elasticsearch/versions/5.3.0/assets/confluent.png"
    },
    "archive": {
      "name": "confluentinc-kafka-connect-elasticsearch-5.3.0.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-elasticsearch/versions/5.3.0/confluentinc-kafka-connect-elasticsearch-5.3.0.zip",
      "mime_type": "application/zip",
      "md5": "494c9ea0a8019733571e696267507fd6",
      "sha1": "e78b2e0dbff48786ab0b94ac11af0674314ab08f",
      "asc": null
    },
    "docker_image": {
      "namespace": "confluentinc",
      "name": "cp-kafka-connect",
      "tag": "5.3.0",
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Community License",
        "url": "http://www.confluent.io/confluent-community-license",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": "2019-07-19",
    "tags": [
      "analytics",
      "search",
      "Elastic",
      "elasticsearch",
      "log"
    ],
    "requirements": [
      "Elasticsearch 2.x, 5.x, or 6.x"
    ],
    "signatures": null,
    "last_modified": 1563568863000
  },
  {
    "name": "kafka-connect-hdfs",
    "version": "5.3.0",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-hdfs/versions/5.3.0",
    "title": "Kafka Connect HDFS",
    "description": "The HDFS connector allows you to export data from Kafka topics to HDFS files in a variety of formats and integrates with Hive to make data immediately available for querying with HiveQL.\n\nThe connector periodically polls data from Kafka and writes them to HDFS. The data from each Kafka topic is partitioned by the provided partitioner and divided into chunks. Each chunk of data is represented as an HDFS file with topic, Kafka partition, start and end offsets of this data chunk in the filename. If no partitioner is specified in the configuration, the default partitioner which preserves the Kafka partitioning is used. The size of each data chunk is determined by the number of records written to HDFS, the time written to HDFS and schema compatibility.\n\nThe HDFS connector integrates with Hive and when it is enabled, the connector automatically creates an external Hive partitioned table for each Kafka topic and updates the table according to the available data in HDFS.",
    "logo": null,
    "documentation_url": "https://docs.confluent.io/5.3.0/connect/connect-hdfs/docs/index.html",
    "source_url": "https://github.com/confluentinc/kafka-connect-hdfs",
    "support": {
      "provider_name": "Confluent, Inc.",
      "summary": "Confluent supports the HDFS sink connector alongside community members as part of its Confluent Platform offering.",
      "url": "https://docs.confluent.io/current/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-hdfs/versions/5.3.0/assets/confluent.png"
    },
    "owner": {
      "username": "confluentinc",
      "type": "Organization",
      "name": "Confluent, Inc.",
      "url": "https://confluent.io/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-hdfs/versions/5.3.0/assets/confluent.png"
    },
    "archive": {
      "name": "confluentinc-kafka-connect-hdfs-5.3.0.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-hdfs/versions/5.3.0/confluentinc-kafka-connect-hdfs-5.3.0.zip",
      "mime_type": "application/zip",
      "md5": "fe392e060b77908e62af669367273006",
      "sha1": "4a6c50c68c58230bd150406a85b7b5a9184ebb46",
      "asc": null
    },
    "docker_image": {
      "namespace": "confluentinc",
      "name": "cp-kafka-connect",
      "tag": "5.3.0",
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Community License",
        "url": "http://www.confluent.io/confluent-community-license",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": "2019-07-19",
    "tags": [
      "hive",
      "hdfs",
      "hadoop"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1563568883000
  },
  {
    "name": "kafka-connect-s3-source",
    "version": "1.0.0-preview",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-s3-source/versions/1.0.0-preview",
    "title": "Kafka Connect S3 Source",
    "description": "A Kafka Connect plugin for S3",
    "logo": null,
    "documentation_url": "https://docs.confluent.io/current/connect/kafka-connect-s3-source/",
    "source_url": null,
    "support": {
      "provider_name": null,
      "summary": "Confluent is introducing this preview connector to\ngain early feedback from developers. It should only be used for\nevaluation and non-production testing purposes or to provide\nfeedback to Confluent and is subject to the\n<a href=\"https://www.confluent.io/confluent-software-evaluation-license/\">Confluent Software Evaluation License.</a>\nConfluent will provide support for this connector for evaluation and non-production testing purposes.\nComments, questions and suggestions related to preview features\nare encouraged. Confluent customers may submit questions and suggestions, and file support tickets via the\n<a href=\"https://support.confluent.io/\">Confluent Support Portal.</a>",
      "url": null,
      "logo": null
    },
    "owner": {
      "username": "confluentinc",
      "type": null,
      "name": "Confluent, Inc.",
      "url": null,
      "logo": null
    },
    "archive": {
      "name": "confluentinc-kafka-connect-s3-source-1.0.0-preview.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-s3-source/versions/1.0.0-preview/confluentinc-kafka-connect-s3-source-1.0.0-preview.zip",
      "mime_type": "application/zip",
      "md5": "387040df3b014f5d4f065dbb9d1c3709",
      "sha1": "6bbcbe3ce16b3d09ca63808c3e7eb64c73a63d28",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Software Evaluation License",
        "url": "https://www.confluent.io/software-evaluation-license",
        "logo": null
      }
    ],
    "component_types": [
      "source"
    ],
    "release_date": "2019-07-17",
    "tags": [
      "Object Storage",
      "S3",
      "Amazon",
      "AWS"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1563406936000
  },
  {
    "name": "kafka-connect-http",
    "version": "1.0.2",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-http/versions/1.0.2",
    "title": "Kafka Connect Http Sink Connector",
    "description": "The Kafka Connect HTTP Sink Connector integrates Kafka with an API via HTTP or HTTPS.\nThe connector consumes records from Kafka topic(s) and converts each record value to a String before\nsending it in the request body to the configured <pre>http.api.url</pre>, which optionally can\nreference the record key and/or topic name. The targeted API must support either a <pre>POST</pre>\nor <pre>PUT</pre> request.\n\n<p>The connector batches records up to the set <pre>batch.max.size</pre> before sending the batched\nrequest to the API. Each record is converted to its String representation and then separated with\nthe <pre>batch.separator</pre>.\n\n<p>The HTTP Sink Connector supports connecting to APIs using SSL along with Basic Authentication,\nOAuth2, or a Proxy Authentication Server.",
    "logo": null,
    "documentation_url": "https://docs.confluent.io/current/connect/kafka-connect-http/",
    "source_url": null,
    "support": {
      "provider_name": null,
      "summary": "This connector is <a href=\"https://www.confluent.io/subscription/\">supported by Confluent</a> as part of a\n<a href=\"https://www.confluent.io/product/confluent-platform/\">Confluent Platform</a> subscription.",
      "url": null,
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-http/versions/1.0.2/assets/confluent.png"
    },
    "owner": {
      "username": "confluentinc",
      "type": "Organization",
      "name": "Confluent, Inc.",
      "url": "https://confluent.io/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-http/versions/1.0.2/assets/confluent.png"
    },
    "archive": {
      "name": "confluentinc-kafka-connect-http-1.0.2.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-http/versions/1.0.2/confluentinc-kafka-connect-http-1.0.2.zip",
      "mime_type": "application/zip",
      "md5": "ebedaddf3985676852f5e686afa33ae4",
      "sha1": "f0a29fea9cfcc545939f2c1f6bbe2c2f33f1f1d0",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Software Evaluation License",
        "url": "https://www.confluent.io/software-evaluation-license",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": "2019-08-06",
    "tags": [
      "REST",
      "service",
      "HTTP",
      "basic auth",
      "oauth2"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1565111623000
  },
  {
    "name": "kafka-connect-datagen",
    "version": "0.1.3",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-datagen/versions/0.1.3",
    "title": "Kafka Connect Datagen",
    "description": "For demos only: A Kafka Connect connector for generating mock data, not suitable for production",
    "logo": null,
    "documentation_url": "https://github.com/confluentinc/kafka-connect-datagen/blob/master/README.md",
    "source_url": "https://github.com/confluentinc/kafka-connect-datagen",
    "support": {
      "provider_name": "Community Support",
      "summary": "This connector is open source at https://github.com/confluentinc/kafka-connect-datagen and supported by community members.",
      "url": "https://github.com/confluentinc/kafka-connect-datagen",
      "logo": null
    },
    "owner": {
      "username": "confluentinc",
      "type": "Organization",
      "name": "Confluent, Inc.",
      "url": "https://confluent.io/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-datagen/versions/0.1.3/assets/confluent.png"
    },
    "archive": {
      "name": "confluentinc-kafka-connect-datagen-0.1.3.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-datagen/versions/0.1.3/confluentinc-kafka-connect-datagen-0.1.3.zip",
      "mime_type": "application/zip",
      "md5": "b95a90b7afb0882e06e9fadade5a76de",
      "sha1": "375e2f8fc62976cf5fdb30d1b93fc89f30564b0e",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Apache License 2.0",
        "url": "https://www.apache.org/licenses/LICENSE-2.0",
        "logo": null
      }
    ],
    "component_types": [
      "source"
    ],
    "release_date": "2019-05-07",
    "tags": [
      "datagen",
      "generator",
      "demo"
    ],
    "requirements": [
      "Confluent Platform 4.x or later",
      "Apache Kafka 1.x or later"
    ],
    "signatures": null,
    "last_modified": 1557188929000
  },
  {
    "name": "kafka-connect-vertica",
    "version": "1.0.0-preview",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-vertica/versions/1.0.0-preview",
    "title": "Kafka Connect Vertica",
    "description": "Kafka Connect plugin for writing data to HPE Vertica.",
    "logo": null,
    "documentation_url": "https://docs.confluent.io/",
    "source_url": null,
    "support": {
      "provider_name": null,
      "summary": "Confluent is introducing this preview connector to gain early feedback from developers. It should only be used for evaluation and non-production testing purposes or to provide feedback to Confluent and is subject to the <a href=\"https://www.confluent.io/confluent-software-evaluation-license/\">Confluent Software Evaluation License</a>. Confluent will provide support for this connector for evaluation and non-production testing purposes.\n\nComments, questions and suggestions related to preview features are encouraged. Confluent customers may submit questions and suggestions, and file support tickets via the <a href=\"https://support.confluent.io/\">Confluent Support Portal</a>.",
      "url": null,
      "logo": null
    },
    "owner": {
      "username": "confluentinc",
      "type": null,
      "name": "Confluent, Inc.",
      "url": null,
      "logo": null
    },
    "archive": {
      "name": "confluentinc-kafka-connect-vertica-1.0.0-preview.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-vertica/versions/1.0.0-preview/confluentinc-kafka-connect-vertica-1.0.0-preview.zip",
      "mime_type": "application/zip",
      "md5": "607e477e34cdbe7b5913fd366ecc4298",
      "sha1": "3634d9bdbcd8e8c7ab5bfeabf706497af04c0088",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Software Evaluation License",
        "url": "https://www.confluent.io/software-evaluation-license",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": "2018-10-18",
    "tags": [
      "Vertica",
      "Database"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1554506876000
  },
  {
    "name": "kafka-connect-cassandra",
    "version": "1.1.3",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-cassandra/versions/1.1.3",
    "title": "Kafka Connect Cassandra",
    "description": "The Confluent Cassandra Sink Connector is used to move messages from Kafka into <a href=\"http://cassandra.apache.org/\">Apache Cassandra</a>.\nThe currently-supported versions of Cassandra are 2.1, 2.2, and 3.0.\nIt can be used for free for 30 days, but after that does require a Confluent Enterprise license. <a href=\"https://www.confluent.io/contact/\">Contact Confluent</a> for more details.",
    "logo": null,
    "documentation_url": "https://docs.confluent.io/current/connect/kafka-connect-cassandra/",
    "source_url": null,
    "support": {
      "provider_name": "Confluent, Inc.",
      "summary": "This connector is <a href=\"https://www.confluent.io/subscription\">fully supported by\nConfluent</a> as of Confluent Platform 5.0.0, as part of a\n<a href=\"https://www.confluent.io/product/confluent-enterprise/\">Confluent Enterprise Platform</a> subscription.",
      "url": null,
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-cassandra/versions/1.1.3/assets/confluent.png"
    },
    "owner": {
      "username": "confluentinc",
      "type": "Organization",
      "name": "Confluent, Inc.",
      "url": "https://www.confluent.io",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-cassandra/versions/1.1.3/assets/confluent.png"
    },
    "archive": {
      "name": "confluentinc-kafka-connect-cassandra-1.1.3.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-cassandra/versions/1.1.3/confluentinc-kafka-connect-cassandra-1.1.3.zip",
      "mime_type": "application/zip",
      "md5": "1322439a5260c203f1c7540cb1ee3ff5",
      "sha1": "5690520fcf824ddd3491d28162f0f9ce63b90889",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Software Evaluation License",
        "url": "https://www.confluent.io/software-evaluation-license",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": "2019-05-22",
    "tags": [
      "Cassandra",
      "Database"
    ],
    "requirements": [
      "Cassandra version 2.1, 2.2, or 3.0"
    ],
    "signatures": null,
    "last_modified": 1558544165000
  },
  {
    "name": "kafka-connect-ibmmq",
    "version": "5.3.0",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-ibmmq/versions/5.3.0",
    "title": "Kafka Connect IBM MQ Source",
    "description": "The IBM MQ Source Connector is used to read messages from an IBM MQ cluster and write them to a Kafka topic.\n\nIt is included in <a href=\"https://www.confluent.io/product/confluent-enterprise/\">Confluent Enterprise Platform</a>, or can be downloaded and installed separately. It can be used for free for 30 days, but after that does require an Enterprise license. <a href=\"https://www.confluent.io/contact/\">Contact Confluent</a> for more details.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-ibmmq/versions/5.3.0/assets/ibm-mq.jpg",
    "documentation_url": "https://docs.confluent.io/5.3.0/connect/connect-jms/kafka-connect-ibmmq/docs/index.html",
    "source_url": null,
    "support": {
      "provider_name": "Confluent, Inc.",
      "summary": "This connector is <a href=\"http://confluent.io/subscription/\">fully supported by\nConfluent</a> as part of a\n<a href=\"https://www.confluent.io/product/confluent-enterprise/\">Confluent Enterprise Platform</a> subscription.",
      "url": "http://confluent.io/subscription/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-ibmmq/versions/5.3.0/assets/confluent.png"
    },
    "owner": {
      "username": "confluentinc",
      "type": "Organization",
      "name": "Confluent, Inc.",
      "url": "http://confluent.io",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-ibmmq/versions/5.3.0/assets/confluent.png"
    },
    "archive": {
      "name": "confluentinc-kafka-connect-ibmmq-5.3.0.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-ibmmq/versions/5.3.0/confluentinc-kafka-connect-ibmmq-5.3.0.zip",
      "mime_type": "application/zip",
      "md5": "02cbc548a07c1307946e82700fb95d2a",
      "sha1": "1807a42abc08f6f75c6377c975321cf878d752dc",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Software Evaluation License",
        "url": "https://www.confluent.io/software-evaluation-license",
        "logo": null
      }
    ],
    "component_types": [
      "source"
    ],
    "release_date": "2019-07-22",
    "tags": [
      "JMS",
      "IBM MQ",
      "Message Broker"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1563827100000
  },
  {
    "name": "kafka-connect-jms-sink",
    "version": "1.1.0-preview",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-jms-sink/versions/1.1.0-preview",
    "title": "Kafka Connect JMS Sink",
    "description": "The Kafka Connect JMS Sink Connector integrates Kafka with JMS-compliant brokers such as ActiveMQ, Solace, TIBCO EMS, and others.\nThe connector consumes records from Kafka topic(s) and converts each record value to either a JMS <pre>TextMessage</pre> or\n<pre>BytesMessage</pre> before producing the JMS Message to the broker.\n<p>The connector does not include the client jars for the JMS system. You will have to include these in the plugin directory. See the documentation for more details on this.\n<p>Prerequisites include:\n<ol>\n<li>Kafka Broker: Confluent Platform 3.3.0 or above, or Kafka 0.11.0 or above</li>\n<li>Kafka Connect: Confluent Platform 4.1.0 or above, or Kafka 1.1.0 or above (requires header support in Connect)</li>\n<li>Java 1.8</li>\n<li>JMS 1.1+ Client Jars</li>\n</ol>",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-jms-sink/versions/1.1.0-preview/assets/jms.jpeg",
    "documentation_url": "https://docs.confluent.io/current/connect/kafka-connect-jms/sink",
    "source_url": null,
    "support": {
      "provider_name": "Confluent, Inc.",
      "summary": "Confluent is introducing this preview connector to\ngain early feedback from developers. It should only be used for\nevaluation and non-production testing purposes or to provide\nfeedback to Confluent and is subject to the\n<a href=\"https://www.confluent.io/confluent-software-evaluation-license/\">Confluent\nSoftware Evaluation License.</a>\nConfluent will provide support for this connector for evaluation and non-production\ntesting purposes.\nComments, questions and suggestions related to preview features\nare encouraged. Confluent customers may submit questions and suggestions, and file\nsupport tickets via the\n<a href=\"https://support.confluent.io/\">Confluent Support Portal.</a>",
      "url": "http://confluent.io/subscription/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-jms-sink/versions/1.1.0-preview/assets/confluent.png"
    },
    "owner": {
      "username": "confluentinc",
      "type": "Organization",
      "name": "Confluent, Inc.",
      "url": "https://confluent.io/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-jms-sink/versions/1.1.0-preview/assets/confluent.png"
    },
    "archive": {
      "name": "confluentinc-kafka-connect-jms-sink-1.1.0-preview.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-jms-sink/versions/1.1.0-preview/confluentinc-kafka-connect-jms-sink-1.1.0-preview.zip",
      "mime_type": "application/zip",
      "md5": "945ffba8040c93e8c3d3c0044fbea73e",
      "sha1": "22402cc4f8e31f2fdf2e222070eddf67c677b49a",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Software Evaluation License",
        "url": "https://www.confluent.io/software-evaluation-license",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": "2019-08-20",
    "tags": [
      "JMS",
      "Java Message Service",
      "Message Broker"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1566342705000
  },
  {
    "name": "kafka-connect-ibmmq-sink",
    "version": "1.1.0",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-ibmmq-sink/versions/1.1.0",
    "title": "Kafka Connect IBM MQ Sink",
    "description": "The Kafka Connect IBM MQ Sink Connector integrates Kafka with IBM MQ.\nThe connector consumes records from Kafka topic(s) and converts each record value to either a JMS <pre>TextMessage</pre> or\n<pre>BytesMessage</pre> before producing the JMS Message to IBM MQ.\n<p>Prerequisites include:\n<ol>\n<li>Kafka Broker: Confluent Platform 3.3.0 or above, or Kafka 0.11.0 or above</li>\n<li>Kafka Connect: Confluent Platform 4.1.0 or above, or Kafka 1.1.0 or above (requires header support in Connect)</li>\n<li>Java 1.8</li>\n</ol>",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-ibmmq-sink/versions/1.1.0/assets/ibmmq.png",
    "documentation_url": "https://docs.confluent.io/current/connect/kafka-connect-ibmmq/sink",
    "source_url": null,
    "support": {
      "provider_name": "Confluent, Inc.",
      "summary": "This connector is <a href=\"https://www.confluent.io/subscription/\">supported by Confluent</a> as part of a\n<a href=\"https://www.confluent.io/product/confluent-platform/\">Confluent Platform</a> subscription.",
      "url": "http://confluent.io/subscription/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-ibmmq-sink/versions/1.1.0/assets/confluent.png"
    },
    "owner": {
      "username": "confluentinc",
      "type": "Organization",
      "name": "Confluent, Inc.",
      "url": "https://confluent.io/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-ibmmq-sink/versions/1.1.0/assets/confluent.png"
    },
    "archive": {
      "name": "confluentinc-kafka-connect-ibmmq-sink-1.1.0.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-ibmmq-sink/versions/1.1.0/confluentinc-kafka-connect-ibmmq-sink-1.1.0.zip",
      "mime_type": "application/zip",
      "md5": "22d7140949b52e0b194dfedcfaf73448",
      "sha1": "e0e58ea44157c24424433524a20b1aae5b68229f",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Software Evaluation License",
        "url": "https://www.confluent.io/software-evaluation-license",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": "2019-08-20",
    "tags": [
      "JMS",
      "Java Message Service",
      "IBM MQ",
      "Message Broker"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1566342702000
  },
  {
    "name": "kafka-connect-hdfs3",
    "version": "1.0.2-preview",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-hdfs3/versions/1.0.2-preview",
    "title": "Kafka Connect HDFS 3",
    "description": "The HDFS 3 connector allows you to export data from Kafka topics to HDFS 3.x files in a variety of formats and integrates with Hive to make data immediately available for querying with HiveQL.\n\nThe connector periodically polls data from Kafka and writes them to an HDFS 3.x cluster. The data from each Kafka topic is partitioned by the provided partitioner and divided into chunks. Each chunk of data is represented as an HDFS file with topic, Kafka partition, start and end offsets of this data chunk in the filename. If no partitioner is specified in the configuration, the default partitioner which preserves the Kafka partitioning is used. The size of each data chunk is determined by the number of records written to HDFS, the time written to HDFS and schema compatibility.\n\nThe HDFS connector integrates with Hive and when it is enabled, the connector automatically creates an external Hive partitioned table for each Kafka topic and updates the table according to the available data in HDFS.",
    "logo": null,
    "documentation_url": "https://docs.confluent.io/current/connect/kafka-connect-hdfs/hdfs3/index.html",
    "source_url": null,
    "support": {
      "provider_name": "Confluent, Inc.",
      "summary": "Confluent is introducing this preview connector to\ngain early feedback from developers. It should only be used for\nevaluation and non-production testing purposes or to provide\nfeedback to Confluent and is subject to the\n<a href=\"https://www.confluent.io/confluent-software-evaluation-license/\">Confluent Software Evaluation License.</a>\nComments, questions and suggestions related to preview features\nare encouraged. Confluent customers may submit questions and\nsuggestions via the\n<a href=\"https://support.confluent.io/\">Confluent Support Portal.</a>",
      "url": "http://confluent.io/subscription/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-hdfs3/versions/1.0.2-preview/assets/confluent.png"
    },
    "owner": {
      "username": "confluentinc",
      "type": "Organization",
      "name": "Confluent, Inc.",
      "url": "http://confluent.io",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-hdfs3/versions/1.0.2-preview/assets/confluent.png"
    },
    "archive": {
      "name": "confluentinc-kafka-connect-hdfs3-1.0.2-preview.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-hdfs3/versions/1.0.2-preview/confluentinc-kafka-connect-hdfs3-1.0.2-preview.zip",
      "mime_type": "application/zip",
      "md5": "3212dd3998411a5391d87736a286aa84",
      "sha1": "059af9e136ab186f4a5c3fd6f7553219ab64f05f",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Software Evaluation License",
        "url": "https://www.confluent.io/software-evaluation-license",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": "2019-08-16",
    "tags": [
      "hive",
      "hdfs3",
      "hdfs",
      "hadoop",
      "hadoop3"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1565990259000
  },
  {
    "name": "kafka-connect-mqtt",
    "version": "1.2.3",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-mqtt/versions/1.2.3",
    "title": "Kafka Connect MQTT",
    "description": "A Kafka Connect plugin for sending and receiving data from a Mqtt broker.",
    "logo": null,
    "documentation_url": "https://docs.confluent.io/current/connect/kafka-connect-mqtt/",
    "source_url": null,
    "support": {
      "provider_name": null,
      "summary": "This connector is <a href=\"https://www.confluent.io/subscription/\">supported by Confluent</a> as part of a\n<a href=\"https://www.confluent.io/product/confluent-platform/\">Confluent Platform</a> subscription.",
      "url": "https://docs.confluent.io/current/connect/kafka-connect-mqtt/",
      "logo": null
    },
    "owner": {
      "username": "confluentinc",
      "type": null,
      "name": "Confluent, Inc.",
      "url": null,
      "logo": null
    },
    "archive": {
      "name": "confluentinc-kafka-connect-mqtt-1.2.3.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-mqtt/versions/1.2.3/confluentinc-kafka-connect-mqtt-1.2.3.zip",
      "mime_type": "application/zip",
      "md5": "78e56ced5203a274850387a15a16b0f4",
      "sha1": "8c7fc58b404a44bf58b799f07593f6e850f2b5d0",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Software Evaluation License",
        "url": "https://www.confluent.io/software-evaluation-license",
        "logo": null
      }
    ],
    "component_types": [
      "source",
      "sink"
    ],
    "release_date": "2019-07-13",
    "tags": [
      "MQTT",
      "Internet of Things",
      "IOT"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1562979262000
  },
  {
    "name": "kafka-connect-solace-source",
    "version": "1.0.0-preview",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-solace-source/versions/1.0.0-preview",
    "title": "Kafka Connect Solace Source",
    "description": "The Kafka Connect Solace Source Connector integrates Kafka with Solace PubSub+.\nThe connector consumes records from Solace queues or topics produces them to a Kafka topic.\n<p>Prerequisites include:\n<ol>\n<li>Kafka Broker: Confluent Platform 3.3.0 or above, or Kafka 0.11.0 or above</li>\n<li>Kafka Connect: Confluent Platform 4.1.0 or above, or Kafka 1.1.0 or above (requires header support in Connect)</li>\n<li>Solace JMS Client Library</li>\n<li>Java 1.8</li>\n</ol>",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-solace-source/versions/1.0.0-preview/assets/solace.png",
    "documentation_url": "https://docs.confluent.io/current/connect/kafka-connect-solace/source",
    "source_url": null,
    "support": {
      "provider_name": "Confluent, Inc.",
      "summary": "Confluent is introducing this preview connector to\ngain early feedback from developers. It should only be used for\nevaluation and non-production testing purposes or to provide\nfeedback to Confluent and is subject to the\n<a href=\"https://www.confluent.io/confluent-software-evaluation-license/\">Confluent\nSoftware Evaluation License.</a>\nConfluent will provide support for this connector for evaluation and non-production\ntesting purposes.\nComments, questions and suggestions related to preview features\nare encouraged. Confluent customers may submit questions and suggestions, and file\nsupport tickets via the\n<a href=\"https://support.confluent.io/\">Confluent Support Portal.</a>",
      "url": "http://confluent.io/subscription/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-solace-source/versions/1.0.0-preview/assets/confluent.png"
    },
    "owner": {
      "username": "confluentinc",
      "type": "Organization",
      "name": "Confluent, Inc.",
      "url": "https://confluent.io/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-solace-source/versions/1.0.0-preview/assets/confluent.png"
    },
    "archive": {
      "name": "confluentinc-kafka-connect-solace-source-1.0.0-preview.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-solace-source/versions/1.0.0-preview/confluentinc-kafka-connect-solace-source-1.0.0-preview.zip",
      "mime_type": "application/zip",
      "md5": "8b6765d59e6861f84b0015d187375619",
      "sha1": "bbf399678a140f191d3384178a3ff1882001ddef",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Software Evaluation License",
        "url": "https://www.confluent.io/software-evaluation-license",
        "logo": null
      }
    ],
    "component_types": [
      "source"
    ],
    "release_date": "2019-08-20",
    "tags": [
      "JMS",
      "Java Message Service",
      "Solace",
      "Message Broker",
      "Solace PubSub+"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1566342592000
  },
  {
    "name": "kafka-connect-s3",
    "version": "5.3.0",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-s3/versions/5.3.0",
    "title": "Kafka Connect S3",
    "description": "The S3 connector, currently available as a sink, allows you to export data from Kafka topics to S3 objects in either Avro or JSON formats. In addition, for certain data layouts, S3 connector exports data by guaranteeing exactly-once delivery semantics to consumers of the S3 objects it produces.\n\nBeing a sink, the S3 connector periodically polls data from Kafka and in turn uploads it to S3. A partitioner is used to split the data of every Kafka partition into chunks. Each chunk of data is represented as an S3 object, whose key name encodes the topic, the Kafka partition and the start offset of this data chunk. If no partitioner is specified in the configuration, the default partitioner which preserves Kafka partitioning is used. The size of each data chunk is determined by the number of records written to S3 and by schema compatibility.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-s3/versions/5.3.0/assets/s3.jpg",
    "documentation_url": "https://docs.confluent.io/5.3.0/connect/connect-storage-cloud/kafka-connect-s3/docs/index.html",
    "source_url": "https://github.com/confluentinc/kafka-connect-storage-cloud",
    "support": {
      "provider_name": "Confluent, Inc.",
      "summary": "Confluent supports the S3 sink connector alongside community members as part of its Confluent Platform offering.",
      "url": "https://docs.confluent.io/current/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-s3/versions/5.3.0/assets/confluent.png"
    },
    "owner": {
      "username": "confluentinc",
      "type": "Organization",
      "name": "Confluent, Inc.",
      "url": "https://confluent.io/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-s3/versions/5.3.0/assets/confluent.png"
    },
    "archive": {
      "name": "confluentinc-kafka-connect-s3-5.3.0.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-s3/versions/5.3.0/confluentinc-kafka-connect-s3-5.3.0.zip",
      "mime_type": "application/zip",
      "md5": "7e57a0a4e6ae3b7e3e32d0246f5de24d",
      "sha1": "ce25bec0b6fcc7628e7378b9f559fb13e7fe95af",
      "asc": null
    },
    "docker_image": {
      "namespace": "confluentinc",
      "name": "cp-kafka-connect",
      "tag": "5.3.0",
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Community License",
        "url": "http://www.confluent.io/confluent-community-license",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": "2019-07-19",
    "tags": [
      "s3",
      "aws"
    ],
    "requirements": [
      "AWS S3 bucket with write permissions"
    ],
    "signatures": null,
    "last_modified": 1563568870000
  },
  {
    "name": "kafka-connect-avro-converter",
    "version": "5.3.0",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-avro-converter/versions/5.3.0",
    "title": "Kafka Connect Avro Converter",
    "description": "The Kafka Connect Avro Converter integrates with <a href=\"https://docs.confluent.io/current/schema-registry/docs/intro.html\">Schema Registry</a> to convert data for Kafka Connect to and from Avro format.",
    "logo": null,
    "documentation_url": "https://docs.confluent.io/current/schema-registry/docs/connect.html",
    "source_url": "https://github.com/confluentinc/schema-registry",
    "support": {
      "provider_name": "Confluent, Inc.",
      "summary": "Confluent supports the Avro Converter alongside community members as part of its Confluent Platform offering.",
      "url": "https://docs.confluent.io/current/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-avro-converter/versions/5.3.0/assets/confluent.png"
    },
    "owner": {
      "username": "confluentinc",
      "type": "Organization",
      "name": "Confluent, Inc.",
      "url": "https://confluent.io/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-avro-converter/versions/5.3.0/assets/confluent.png"
    },
    "archive": {
      "name": "confluentinc-kafka-connect-avro-converter-5.3.0.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-avro-converter/versions/5.3.0/confluentinc-kafka-connect-avro-converter-5.3.0.zip",
      "mime_type": "application/zip",
      "md5": "66903447d86b0007a448c5b7df48c7a1",
      "sha1": "8ca611feaf211438ddd85d1f6bea0d213fab238a",
      "asc": null
    },
    "docker_image": {
      "namespace": "confluentinc",
      "name": "cp-kafka-connect",
      "tag": "5.3.0",
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "avro"
      ],
      "single_message_transforms": false,
      "confluent_control_center_integration": false,
      "kafka_connect_api": false,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Apache License 2.0",
        "url": "http://www.apache.org/licenses/LICENSE-2.0.html",
        "logo": null
      }
    ],
    "component_types": [
      "converter"
    ],
    "release_date": "2019-07-19",
    "tags": [
      "schema registry",
      "avro"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1563568878000
  },
  {
    "name": "kafka-connect-jms",
    "version": "5.3.0",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-jms/versions/5.3.0",
    "title": "Kafka Connect JMS Source",
    "description": "The Confluent JMS Source Connector is used to move messages from any JMS-compliant broker into Kafka.\nIt supports any traditional JMS Broker, such as IBM MQ, ActiveMQ, TIBCO EMS, and Solace Appliance.\nThis connector uses JNDI to connect to the JMS broker, consume messages from the specified topic or queue, and write them into the specified Kafka topic.\n\nIt is included in <a href=\"https://www.confluent.io/product/confluent-enterprise/\">Confluent Enterprise Platform</a>, or can be downloaded and installed separately. It can be used for free for 30 days, but after that does require an Enterprise license. <a href=\"https://www.confluent.io/contact/\">Contact Confluent</a> for more details.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-jms/versions/5.3.0/assets/jms.jpeg",
    "documentation_url": "https://docs.confluent.io/5.3.0/connect/connect-jms/kafka-connect-jms/docs/index.html",
    "source_url": null,
    "support": {
      "provider_name": "Confluent, Inc.",
      "summary": "This connector is <a href=\"http://confluent.io/subscription/\">fully supported by\nConfluent</a> as part of a\n<a href=\"https://www.confluent.io/product/confluent-enterprise/\">Confluent Enterprise Platform</a> subscription.",
      "url": "http://confluent.io/subscription/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-jms/versions/5.3.0/assets/confluent.png"
    },
    "owner": {
      "username": "confluentinc",
      "type": "Organization",
      "name": "Confluent, Inc.",
      "url": "http://confluent.io",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-jms/versions/5.3.0/assets/confluent.png"
    },
    "archive": {
      "name": "confluentinc-kafka-connect-jms-5.3.0.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-jms/versions/5.3.0/confluentinc-kafka-connect-jms-5.3.0.zip",
      "mime_type": "application/zip",
      "md5": "e7e7b713f404cd139763b569abb25b13",
      "sha1": "f4c688c76bf6607abf3d83a6dc16e7ff33a55412",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Software Evaluation License",
        "url": "https://www.confluent.io/software-evaluation-license",
        "logo": null
      }
    ],
    "component_types": [
      "source"
    ],
    "release_date": "2019-07-22",
    "tags": [
      "JMS",
      "Message Broker"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1563827057000
  },
  {
    "name": "kafka-connect-tibco-sink",
    "version": "1.1.0-preview",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-tibco-sink/versions/1.1.0-preview",
    "title": "Kafka Connect TIBCO Sink",
    "description": "The Kafka Connect TIBCO Sink Connector integrates Kafka with TIBCO EMS.\nThe connector consumes records from Kafka topic(s) and converts each record value to either a JMS <pre>TextMessage</pre> or\n<pre>BytesMessage</pre> before producing the JMS Message to TIBCO.\n<p>Prerequisites include:\n<ol>\n<li>Kafka Broker: Confluent Platform 3.3.0 or above, or Kafka 0.11.0 or above</li>\n<li>Kafka Connect: Confluent Platform 4.1.0 or above, or Kafka 1.1.0 or above (requires header support in Connect)</li>\n<li>TIBCO JMS Client Library</li>\n<li>Java 1.8</li>\n</ol>",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-tibco-sink/versions/1.1.0-preview/assets/tibco.png",
    "documentation_url": "https://docs.confluent.io/current/connect/kafka-connect-tibco/sink",
    "source_url": null,
    "support": {
      "provider_name": "Confluent, Inc.",
      "summary": "Confluent is introducing this preview connector to\ngain early feedback from developers. It should only be used for\nevaluation and non-production testing purposes or to provide\nfeedback to Confluent and is subject to the\n<a href=\"https://www.confluent.io/confluent-software-evaluation-license/\">Confluent\nSoftware Evaluation License.</a>\nConfluent will provide support for this connector for evaluation and non-production\ntesting purposes.\nComments, questions and suggestions related to preview features\nare encouraged. Confluent customers may submit questions and suggestions, and file\nsupport tickets via the\n<a href=\"https://support.confluent.io/\">Confluent Support Portal.</a>",
      "url": "http://confluent.io/subscription/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-tibco-sink/versions/1.1.0-preview/assets/confluent.png"
    },
    "owner": {
      "username": "confluentinc",
      "type": "Organization",
      "name": "Confluent, Inc.",
      "url": "https://confluent.io/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-tibco-sink/versions/1.1.0-preview/assets/confluent.png"
    },
    "archive": {
      "name": "confluentinc-kafka-connect-tibco-sink-1.1.0-preview.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-tibco-sink/versions/1.1.0-preview/confluentinc-kafka-connect-tibco-sink-1.1.0-preview.zip",
      "mime_type": "application/zip",
      "md5": "343492757c9a8a3deaacea992170773a",
      "sha1": "05b13754e2f6e6ff3ae0f41c27e30fd7bd1c2c57",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Software Evaluation License",
        "url": "https://www.confluent.io/software-evaluation-license",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": "2019-08-20",
    "tags": [
      "JMS",
      "Java Message Service",
      "TIBCO EMS",
      "Message Broker",
      "TIBCO"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1566342710000
  },
  {
    "name": "kafka-connect-rabbitmq",
    "version": "1.1.1",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-rabbitmq/versions/1.1.1",
    "title": "Kafka Connect RabbitMQ",
    "description": "A Kafka Connect connector reading and writing data from RabbitMQ.",
    "logo": null,
    "documentation_url": "https://docs.confluent.io/current/connect/kafka-connect-rabbitmq/",
    "source_url": null,
    "support": {
      "provider_name": "Confluent, Inc.",
      "summary": "This connector is <a href=\"https://www.confluent.io/subscription/\">supported by Confluent</a> as part of a\n<a href=\"https://www.confluent.io/product/confluent-platform/\">Confluent Platform</a> subscription.",
      "url": null,
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-rabbitmq/versions/1.1.1/assets/confluent.png"
    },
    "owner": {
      "username": "confluentinc",
      "type": "Organization",
      "name": "Confluent, Inc.",
      "url": "https://www.confluent.io",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-rabbitmq/versions/1.1.1/assets/confluent.png"
    },
    "archive": {
      "name": "confluentinc-kafka-connect-rabbitmq-1.1.1.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-rabbitmq/versions/1.1.1/confluentinc-kafka-connect-rabbitmq-1.1.1.zip",
      "mime_type": "application/zip",
      "md5": "bc3bc3f4fe607df34f63a7af3dcbac4e",
      "sha1": "4ab3dee8fd45dd75d89bf2dc16e18adb8772d0dc",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Software Evaluation License",
        "url": "https://www.confluent.io/software-evaluation-license",
        "logo": null
      }
    ],
    "component_types": [
      "source",
      "transform"
    ],
    "release_date": "2019-08-20",
    "tags": [
      "RabbitMQ",
      "Messaging"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1566335883000
  },
  {
    "name": "kafka-connect-netezza",
    "version": "1.0.0-preview",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-netezza/versions/1.0.0-preview",
    "title": "Kafka Connect Netezza",
    "description": "A Kafka Connect plugin for Netezza",
    "logo": null,
    "documentation_url": "https://docs.confluent.io/current/connect/kafka-connect-netezza/",
    "source_url": null,
    "support": {
      "provider_name": null,
      "summary": "Confluent is introducing this preview connector to\ngain early feedback from developers. It should only be used for\nevaluation and non-production testing purposes or to provide\nfeedback to Confluent and is subject to the\n<a href=\"https://www.confluent.io/confluent-software-evaluation-license/\">Confluent Software Evaluation License.</a>\nConfluent will provide support for this connector for evaluation and non-production testing purposes.\n\nComments, questions and suggestions related to preview features\nare encouraged. Confluent customers may submit questions and suggestions, and file support tickets via the\n<a href=\"https://support.confluent.io/\">Confluent Support Portal.</a>",
      "url": null,
      "logo": null
    },
    "owner": {
      "username": "confluentinc",
      "type": null,
      "name": "Confluent, Inc.",
      "url": null,
      "logo": null
    },
    "archive": {
      "name": "confluentinc-kafka-connect-netezza-1.0.0-preview.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-netezza/versions/1.0.0-preview/confluentinc-kafka-connect-netezza-1.0.0-preview.zip",
      "mime_type": "application/zip",
      "md5": "5fddf94fa3bd6259dbb9abea4d410d10",
      "sha1": "d8ca7c10a6ab5c7ea44675d8090de95537cab27f",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Software Evaluation License",
        "url": "https://www.confluent.io/software-evaluation-license",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": "2019-08-26",
    "tags": [
      "Warehouse",
      "Netezza",
      "Data Warehouse",
      "Data"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1566833864000
  },
  {
    "name": "kafka-connect-azure-data-lake-gen1-storage",
    "version": "1.1.1",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-azure-data-lake-gen1-storage/versions/1.1.1",
    "title": "Kafka Connect Azure Data Lake Gen1 Sink",
    "description": "The Azure Data Lake Gen1 Sink Connector integrates <a href=\"https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-overview/\">Azure Data Lake Gen1</a> with Apache Kafka.\nThe connector can export data from Apache Kafka® topics to Azure Data Lake Gen1 files in either Avro or JSON formats.\nDepending on your environment, the Azure Data Lake Gen1 connector can export data by guaranteeing exactly-once delivery\nsemantics to consumers of the Azure Data Lake Gen1 files it produces.\n\n<p>The Azure Data Lake Gen1 sink connector periodically polls data from Kafka and in turn uploads it to Azure Data Lake Gen1.\nA partitioner is used to split the data of every Kafka partition into chunks.\nEach chunk of data is represented as an Azure Data Lake Gen1 file. The key name encodes the topic, Kafka partition, and\nstart offset of this data chunk. If no partitioner is specified in the configuration, a default partitioner is used that\npreserves Kafka partitioning. The size of each data chunk is determined by the number of records written to Azure Data Lake Gen1 and by schema compatibility.",
    "logo": null,
    "documentation_url": "https://docs.confluent.io/current/connect/kafka-connect-azure-data-lake-gen1-storage/",
    "source_url": null,
    "support": {
      "provider_name": null,
      "summary": "This connector is <a href=\"https://www.confluent.io/subscription/\">supported by Confluent</a> as part of a\n<a href=\"https://www.confluent.io/product/confluent-platform/\">Confluent Platform</a> subscription.",
      "url": null,
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-azure-data-lake-gen1-storage/versions/1.1.1/assets/confluent.png"
    },
    "owner": {
      "username": "confluentinc",
      "type": "Organization",
      "name": "Confluent, Inc.",
      "url": "https://confluent.io/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-azure-data-lake-gen1-storage/versions/1.1.1/assets/confluent.png"
    },
    "archive": {
      "name": "confluentinc-kafka-connect-azure-data-lake-gen1-storage-1.1.1.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-azure-data-lake-gen1-storage/versions/1.1.1/confluentinc-kafka-connect-azure-data-lake-gen1-storage-1.1.1.zip",
      "mime_type": "application/zip",
      "md5": "77487739ff0f429bdeab91de93126ab3",
      "sha1": "fd603669b5bf991b271eaf5c687106ee9acb9da3",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Software Evaluation License",
        "url": "https://www.confluent.io/software-evaluation-license",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": "2019-08-20",
    "tags": [
      "file storage",
      "exactly once",
      "gen 1",
      "generation 1",
      "data lake",
      "azure"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1566335950000
  },
  {
    "name": "kafka-connect-influxdb",
    "version": "1.1.0-preview",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-influxdb/versions/1.1.0-preview",
    "title": "Kafka Connect InfluxDB",
    "description": "This plugin has a sink for writing data to InfluxDB which will process the data and batch the payload based on the host.",
    "logo": null,
    "documentation_url": "https://docs.confluent.io/current/connect/kafka-connect-influxdb/",
    "source_url": null,
    "support": {
      "provider_name": null,
      "summary": "Confluent is introducing this preview connector to\ngain early feedback from developers. It should only be used for\nevaluation and non-production testing purposes or to provide\nfeedback to Confluent and is subject to the\n<a href=\"https://www.confluent.io/confluent-software-evaluation-license/\">Confluent Software Evaluation License.</a>\nConfluent will provide support for this connector for evaluation and non-production testing purposes.\n\nComments, questions and suggestions related to preview features\nare encouraged. Confluent customers may submit questions and suggestions, and file support tickets via the\n<a href=\"https://support.confluent.io/\">Confluent Support Portal.</a>",
      "url": null,
      "logo": null
    },
    "owner": {
      "username": "confluentinc",
      "type": null,
      "name": "Confluent, Inc.",
      "url": null,
      "logo": null
    },
    "archive": {
      "name": "confluentinc-kafka-connect-influxdb-1.1.0-preview.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-influxdb/versions/1.1.0-preview/confluentinc-kafka-connect-influxdb-1.1.0-preview.zip",
      "mime_type": "application/zip",
      "md5": "94508de0d3caa77d9b41ec9248869923",
      "sha1": "0376e3b9d3835f144e44098a8c16a5bb1286f5ca",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Software Evaluation License",
        "url": "https://www.confluent.io/software-evaluation-license",
        "logo": null
      }
    ],
    "component_types": [
      "source",
      "sink"
    ],
    "release_date": "2019-08-28",
    "tags": [
      "Time Series",
      "Database"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1566975939000
  },
  {
    "name": "kafka-connect-kinesis",
    "version": "1.1.4",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-kinesis/versions/1.1.4",
    "title": "Kafka Connect Kinesis",
    "description": "Kafka Connect plugin for receiving data from Amazon Kinesis",
    "logo": null,
    "documentation_url": "https://docs.confluent.io/current/connect/kafka-connect-kinesis/",
    "source_url": null,
    "support": {
      "provider_name": null,
      "summary": "This connector is <a href=\"https://www.confluent.io/subscription/\">supported by Confluent</a> as part of a\n<a href=\"https://www.confluent.io/product/confluent-platform/\">Confluent Platform</a> subscription.",
      "url": "https://docs.confluent.io/current/connect/kafka-connect-kinesis/",
      "logo": null
    },
    "owner": {
      "username": "confluentinc",
      "type": null,
      "name": "Confluent, Inc.",
      "url": null,
      "logo": null
    },
    "archive": {
      "name": "confluentinc-kafka-connect-kinesis-1.1.4.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-kinesis/versions/1.1.4/confluentinc-kafka-connect-kinesis-1.1.4.zip",
      "mime_type": "application/zip",
      "md5": "be49076822a8061f0aea1572720f1fab",
      "sha1": "be08a84d279e8cb380f99c235ae252f8984f9d52",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Software Evaluation License",
        "url": "https://www.confluent.io/software-evaluation-license",
        "logo": null
      }
    ],
    "component_types": [
      "source"
    ],
    "release_date": "2019-06-02",
    "tags": [
      "Kinesis",
      "AWS"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1559498792000
  },
  {
    "name": "connect-transforms",
    "version": "1.2.1",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/connect-transforms/versions/1.2.1",
    "title": "connect-transformations",
    "description": "A collection of SMTs (single message transforms) for use with Kafka\nConnect. Includes the following:\n\n<p><b>ExtractTopic</b>: Extract data from a message, and use it as\nthe topic name. Can either use the entire key/value (which should be\na string), or use a field from a map or struct.\nUse the concrete transformation type designed for the\nrecord key\n(<code>io.confluent.connect.transforms.ExtractTopic$Key</code>) or\nvalue\n(<code> io.confluent.connect.transforms.ExtractTopic$Value</code>).\n\n<p><b>Drop</b>: Drop either the key or value from a message,\nsetting it to null.\nUse the concrete transformation type designed for the record key\n(<code>io.confluent.connect.transforms.Drop$Key</code>) or value\n(<code>io.confluent.connect.transforms.Drop$Value</code>).",
    "logo": null,
    "documentation_url": "https://docs.confluent.io/5.0.0/connect/transforms/index.html",
    "source_url": null,
    "support": {
      "provider_name": null,
      "summary": "These transformations are <a href=\"https://www.confluent.io/subscription/\">supported by Confluent</a> as part of a\n<a href=\"https://www.confluent.io/product/confluent-platform/\">Confluent Platform</a> subscription.",
      "url": null,
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/connect-transforms/versions/1.2.1/assets/confluent.png"
    },
    "owner": {
      "username": "confluentinc",
      "type": null,
      "name": "Confluent, Inc.",
      "url": null,
      "logo": null
    },
    "archive": {
      "name": "confluentinc-connect-transforms-1.2.1.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/connect-transforms/versions/1.2.1/confluentinc-connect-transforms-1.2.1.zip",
      "mime_type": "application/zip",
      "md5": "e8ddafe92272a62b002ca8a76ef090c1",
      "sha1": "de638473222ff7fb54a75e27ebfca62c5df402b7",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Software License",
        "url": "https://www.confluent.io/software-evaluation-license",
        "logo": null
      }
    ],
    "component_types": [
      "transform"
    ],
    "release_date": "2019-06-28",
    "tags": [
      "transform",
      "field",
      "topic"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1561752865000
  },
  {
    "name": "kafka-connect-gcs",
    "version": "5.0.3",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-gcs/versions/5.0.3",
    "title": "Kafka Connect GCS",
    "description": "The GCS connector, currently available as a sink, allows you to export data from Kafka topics to GCS objects in either Avro or JSON formats.\n\nBeing a sink, the GCS connector periodically polls data from Kafka and in turn uploads it to GCS. A partitioner is used to split the data of every Kafka partition into chunks. Each chunk of data is represented as an GCS object, whose key name encodes the topic,\nthe Kafka partition and the start offset of this data chunk. If no partitioner is specified in the configuration, the default partitioner which preserves Kafka partitioning is used. The size of each data chunk is determined by the number of records written to GCS and by schema compatibility.\nIt is included in <a href=\"https://www.confluent.io/product/confluent-enterprise/\">Confluent Enterprise Platform</a>, or can be downloaded and installed separately. It can be used for free for 30 days, but after that does require an Enterprise license. <a href=\"https://www.confluent.io/contact/\">Contact Confluent</a> for more details.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-gcs/versions/5.0.3/assets/googlecloud.png",
    "documentation_url": "https://docs.confluent.io/current/connect/kafka-connect-gcs/index.html",
    "source_url": null,
    "support": {
      "provider_name": "Confluent, Inc.",
      "summary": "This connector is <a href=\"https://www.confluent.io/subscription/\">fully supported by Confluent</a> as part of a\n<a href=\"https://www.confluent.io/product/confluent-enterprise/\">Confluent Enterprise Platform</a> subscription.",
      "url": "https://docs.confluent.io/current/",
      "logo": null
    },
    "owner": {
      "username": "confluentinc",
      "type": "Organization",
      "name": "Confluent, Inc.",
      "url": "https://confluent.io/",
      "logo": null
    },
    "archive": {
      "name": "confluentinc-kafka-connect-gcs-5.0.3.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-gcs/versions/5.0.3/confluentinc-kafka-connect-gcs-5.0.3.zip",
      "mime_type": "application/zip",
      "md5": "444f51845711220ccb8f7453cba66f23",
      "sha1": "64d80b7b9103db8da7d526d3c27da94f39d79676",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Software Evaluation License",
        "url": "https://www.confluent.io/software-evaluation-license",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": "2019-08-01",
    "tags": [
      "cloud",
      "gcp",
      "gcs",
      "google",
      "storage",
      "platform"
    ],
    "requirements": [
      "GCS bucket with write permissions"
    ],
    "signatures": null,
    "last_modified": 1564680869000
  },
  {
    "name": "kafka-connect-sqs",
    "version": "1.0.1-preview",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-sqs/versions/1.0.1-preview",
    "title": "Kafka Connect SQS",
    "description": "The AWS SQS source connector allows moving data from AWS SQS to Kafka.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-sqs/versions/1.0.1-preview/assets/sqs.png",
    "documentation_url": "https://docs.confluent.io/current/connect/kafka-connect-sqs",
    "source_url": "https://github.com/confluentinc/kafka-connect-sqs",
    "support": {
      "provider_name": "Confluent, Inc.",
      "summary": "This connector is not currently supported and is instead provided as a preview covered by the Confluent Software Evaluation License.",
      "url": "https://docs.confluent.io/current/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-sqs/versions/1.0.1-preview/assets/confluent.png"
    },
    "owner": {
      "username": "confluentinc",
      "type": "Organization",
      "name": "Confluent, Inc.",
      "url": "https://confluent.io/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-sqs/versions/1.0.1-preview/assets/confluent.png"
    },
    "archive": {
      "name": "confluentinc-kafka-connect-sqs-1.0.1-preview.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-sqs/versions/1.0.1-preview/confluentinc-kafka-connect-sqs-1.0.1-preview.zip",
      "mime_type": "application/zip",
      "md5": "782bf71b24e7db6d83e86fe6d674d9d7",
      "sha1": "16c3f53bc463ae4964418232418e1e24ba6f9b7e",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Confluent Software Evaluation License",
        "url": "https://www.confluent.io/software-evaluation-license",
        "logo": null
      }
    ],
    "component_types": [
      "source"
    ],
    "release_date": "2019-07-15",
    "tags": [
      "SQS",
      "FIFO",
      "AWS",
      "Queue"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1563165338000
  },
  {
    "name": "sdc",
    "version": "3.9.0",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/streamsets/sdc/versions/3.9.0",
    "title": "StreamSets Data Collector",
    "description": "StreamSets simplifies the process of building, executing and operating modern datadlows.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/streamsets/sdc/versions/3.9.0/assets/logo.png",
    "documentation_url": "https://streamsets.com/documentation-page/",
    "source_url": "https://streamsets.com/opensource",
    "support": {
      "provider_name": "StreamSets",
      "summary": "StreamSets provides full support for this integration. For more information. For more information, see <a style=\"color:#4597cb\" href=\"https://www.streamsets.com\">https://www.streamsets.com</a>.",
      "url": null,
      "logo": null
    },
    "owner": {
      "username": "streamsets",
      "type": "Organization",
      "name": "StreamSets",
      "url": "https://www.streamsets.com",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/streamsets/sdc/versions/3.9.0/assets/logo.png"
    },
    "archive": null,
    "docker_image": null,
    "confluent_verified": {
      "level": "standard"
    },
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": null,
      "confluent_control_center_integration": null,
      "kafka_connect_api": null,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Apache 2.0",
        "url": null,
        "logo": null
      }
    ],
    "component_types": [
      "source"
    ],
    "release_date": null,
    "tags": [
      "pipelines",
      "streamsets",
      "etl"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1565590783000
  },
  {
    "name": "kafka-connect-rockset",
    "version": "1.0.1",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/rockset/kafka-connect-rockset/versions/1.0.1",
    "title": "Rockset Kafka Connector",
    "description": "Kafka Connect for Rockset is a Kafka Connect Sink.\n\nThis connector helps you load your data from Kafka Streams into Rockset collections through the Rockset Streaming Write API and runs in both standalone and distributed mode.\n\nOnly valid JSON and Avro documents can be read from Kafka Streams and written to Rockset collections by Kafka Connect for Rockset.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/rockset/kafka-connect-rockset/versions/1.0.1/assets/RsLogoRGB_Rockset-Color.png",
    "documentation_url": "https://docs.rockset.com/apache-kafka/",
    "source_url": null,
    "support": {
      "provider_name": "Rockset",
      "summary": "Rockset supports the Rockset Kafka Connector.",
      "url": "https://docs.rockset.com",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/rockset/kafka-connect-rockset/versions/1.0.1/assets/RsLogoRGB_Rockset-Color.png"
    },
    "owner": {
      "username": "rockset",
      "type": "Organization",
      "name": "Rockset",
      "url": "https://rockset.com",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/rockset/kafka-connect-rockset/versions/1.0.1/assets/RsLogoRGB_Rockset-Color.png"
    },
    "archive": {
      "name": "rockset-kafka-connect-rockset-1.0.1.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/rockset/kafka-connect-rockset/versions/1.0.1/rockset-kafka-connect-rockset-1.0.1.zip",
      "mime_type": "application/zip",
      "md5": "ac7ae776606820d91d10348d50a578e7",
      "sha1": "2975b185d93ddd0d5814df7f0028779bfc15647f",
      "asc": null
    },
    "docker_image": {
      "namespace": "jcustenborder",
      "name": "kafka-connect-docker",
      "tag": null,
      "registry": null
    },
    "confluent_verified": {
      "level": "gold"
    },
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "The Apache License, Version 2.0",
        "url": "https://www.apache.org/licenses/LICENSE-2.0",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": "2019-09-03",
    "tags": [
      "analytics",
      "search",
      "Rockset",
      "SQL"
    ],
    "requirements": [
      "Kafka version 1.0.0+",
      "An active Rockset account",
      "Java 8+"
    ],
    "signatures": null,
    "last_modified": 1567813075000
  },
  {
    "name": "kafka-connect-iothub",
    "version": "0.6",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/microsoft/kafka-connect-iothub/versions/0.6",
    "title": "Kafka Connect IoT Hub",
    "description": "Kafka Connect Azure IoT Hub consists of 2 connectors - a source connector and a sink connector. The source connector is used to pump data from <a href=\"https://azure.microsoft.com/en-us/services/iot-hub/\">Azure IoT Hub</a> to <a href=\"https://kafka.apache.org/\">Apache Kafka</a>, whereas the sink connector reads messages from Kafka and sends them to IoT devices via <a href=\"https://azure.microsoft.com/en-us/services/iot-hub/\">Azure IoT Hub</a>. When used in tandem, the 2 connectors allow communicating with IoT devices by simply posting and reading messages to/from Kafka topics. This should make it easier for open source systems and other systems that already interface with Kafka to communicate with Azure IoT devices.\nFor more information on the capabilities of the connectors and how to use them, please refer to <a href=\"https://github.com/Azure/toketi-kafka-connect-iothub/blob/master/README_Source.md\">source connector</a> and <a href=\"https://github.com/Azure/toketi-kafka-connect-iothub/blob/master/README_Sink.md\">sink connector</a>.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/microsoft/kafka-connect-iothub/versions/0.6/assets/Azure.png",
    "documentation_url": "https://github.com/Azure/toketi-kafka-connect-iothub/blob/master/README_Sink.md",
    "source_url": "https://github.com/Azure/toketi-kafka-connect-iothub/",
    "support": null,
    "owner": {
      "username": "microsoft",
      "type": "Organization",
      "name": "Microsoft Corporation",
      "url": "https://microsoft.com",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/microsoft/kafka-connect-iothub/versions/0.6/assets/Microsoft.jpg"
    },
    "archive": {
      "name": "microsoft-kafka-connect-iothub-0.6.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/microsoft/kafka-connect-iothub/versions/0.6/microsoft-kafka-connect-iothub-0.6.zip",
      "mime_type": "application/zip",
      "md5": "74bffa5e38470706ca33376a2f7a4821",
      "sha1": "28a1b64facf94834f3ceda62061994c9cfee05a1",
      "asc": null
    },
    "docker_image": null,
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "MIT",
        "url": "https://github.com/Azure/toketi-kafka-connect-iothub/blob/master/LICENSE",
        "logo": null
      }
    ],
    "component_types": [
      "source",
      "sink"
    ],
    "release_date": null,
    "tags": [
      "azure",
      "iot",
      "messaging"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1535074643000
  },
  {
    "name": "attunity-cdc",
    "version": "6.1.0",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/attunity/attunity-cdc/versions/6.1.0",
    "title": "Attunity Replicate",
    "description": "Used by enterprises around the world, Attunity Replicate is a software solution that accelerates data replication, ingest, and streaming across a wide range of databases, data warehouses and data platforms. For more information go to: <a style=\"color:#4597cb\" href=\"https://www.attunity.com/confluent\">www.attunity.com/confluent</a>.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/attunity/attunity-cdc/versions/6.1.0/assets/logo.jpg",
    "documentation_url": "https://discover.attunity.com/contact-us",
    "source_url": null,
    "support": {
      "provider_name": "Atunity",
      "summary": "For more information, go <a style=\"color:#4597cb\" href=\"https://discover.attunity.com/contact-us\">here</a>.",
      "url": null,
      "logo": null
    },
    "owner": {
      "username": "attunity",
      "type": "Organization",
      "name": "Attunity ",
      "url": "https://discover.attunity.com/contact-us",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/attunity/attunity-cdc/versions/6.1.0/assets/logo.jpg"
    },
    "archive": null,
    "docker_image": null,
    "confluent_verified": {
      "level": "standard"
    },
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": null,
      "confluent_control_center_integration": null,
      "kafka_connect_api": null,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Proprietary",
        "url": null,
        "logo": null
      }
    ],
    "component_types": [
      "source"
    ],
    "release_date": null,
    "tags": [
      "CDC"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1553530368000
  },
  {
    "name": "kafka-connect-hbase",
    "version": "1.0.1",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/nishutayal/kafka-connect-hbase/versions/1.0.1",
    "title": "Kafka Connect HBase Sink",
    "description": "It's a basic Apache Kafka Connect SinkConnector\nwhich allows moving data from Kafka topics into HBase tables.",
    "logo": null,
    "documentation_url": "https://github.com/tayalnishu/kafka-connect-hbase/blob/master/README.md",
    "source_url": "https://github.com/tayalnishu/kafka-connect-hbase",
    "support": {
      "provider_name": "Open Source Community",
      "summary": "Support provided through community involvement.",
      "url": "https://github.com/tayalnishu/kafka-connect-hbase/issues",
      "logo": null
    },
    "owner": {
      "username": "nishutayal",
      "type": null,
      "name": "Nishu Tayal",
      "url": null,
      "logo": null
    },
    "archive": {
      "name": "nishutayal-kafka-connect-hbase-1.0.1.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/nishutayal/kafka-connect-hbase/versions/1.0.1/nishutayal-kafka-connect-hbase-1.0.1.zip",
      "mime_type": "application/zip",
      "md5": "73a83fa6c6ffd9970c5079ee08dacc4d",
      "sha1": "77381db57665f773a80f70e759f36bf026da5970",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Apache License 2.0",
        "url": "http://www.apache.org/licenses/LICENSE-2.0.html",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": "2019-08-06",
    "tags": [
      "hbase"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1565102680000
  },
  {
    "name": "couchbase-connector",
    "version": "3.4.4",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/couchbase/couchbase-connector/versions/3.4.4",
    "title": "Couchbase DB Connector",
    "description": "kafka-connect-couchbase is a Kafka Connect plugin for transferring data between Couchbase Server and Kafka. It includes a \"source connector\" for publishing document change notifications from Couchbase to a Kafka topic, as well as a \"sink connector\" that subscribes to one or more Kafka topics and writes the messages to Couchbase.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/couchbase/couchbase-connector/versions/3.4.4/assets/CouchDB2.jpg",
    "documentation_url": "https://docs.couchbase.com/kafka-connector/3.4/index.html",
    "source_url": "https://github.com/couchbase/kafka-connect-couchbase",
    "support": {
      "provider_name": "Couchbase",
      "summary": "Officially supported by Couchbase.",
      "url": "http://support.couchbase.com",
      "logo": null
    },
    "owner": {
      "username": "couchbase",
      "type": "Organization",
      "name": "Couchbase",
      "url": "https://www.couchbase.com/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/couchbase/couchbase-connector/versions/3.4.4/assets/CouchDB2.jpg"
    },
    "archive": null,
    "docker_image": null,
    "confluent_verified": {
      "level": "gold"
    },
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Apache 2.0",
        "url": null,
        "logo": null
      }
    ],
    "component_types": [
      "source",
      "sink"
    ],
    "release_date": null,
    "tags": [
      "Database"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1560806194000
  },
  {
    "name": "kafka-connect-hec-sink",
    "version": "1.0",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/humio/kafka-connect-hec-sink/versions/1.0",
    "title": "Kafka Connect Humio Sink",
    "description": "It's a basic Apache Kafka Connect SinkConnector which allows moving data from Kafka topics into Humio.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/humio/kafka-connect-hec-sink/versions/1.0/assets/humio-logo.png",
    "documentation_url": "https://github.com/humio/kafka-connect-hec-sink/blob/master/README.md",
    "source_url": "https://github.com/humio/kafka-connect-hec-sink",
    "support": {
      "provider_name": "Humio",
      "summary": "Supprort is available from Humio.",
      "url": "http://humio.com/",
      "logo": null
    },
    "owner": {
      "username": "humio",
      "type": "Organization",
      "name": "Humio",
      "url": "https://humio.com/",
      "logo": null
    },
    "archive": {
      "name": "humio-kafka-connect-hec-sink-1.0.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/humio/kafka-connect-hec-sink/versions/1.0/humio-kafka-connect-hec-sink-1.0.zip",
      "mime_type": "application/zip",
      "md5": "6eb2aca6037a1141782c23c629553a87",
      "sha1": "ea5be07ef46a1f0e025a5d05c68b5eba86b15bbe",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": {
      "level": "gold"
    },
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": null,
    "component_types": [
      "sink"
    ],
    "release_date": "2019-07-09",
    "tags": [
      "search",
      "humio",
      "log aggregation",
      "logging",
      "logs"
    ],
    "requirements": [
      "humio"
    ],
    "signatures": null,
    "last_modified": 1562710831000
  },
  {
    "name": "kafka-connect-rss",
    "version": "0.1.0",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/kaliy/kafka-connect-rss/versions/0.1.0",
    "title": "Kafka Connect RSS Source",
    "description": "Kafka RSS source connector allows moving data from RSS and Atom feeds to kafka.\nIt continuously polling feeds on the given URLs and sends new items to kafka.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/kaliy/kafka-connect-rss/versions/0.1.0/assets/rss_logo.png",
    "documentation_url": "https://github.com/kaliy/kafka-connect-rss/blob/master/README.md",
    "source_url": "https://github.com/kaliy/kafka-connect-rss",
    "support": {
      "provider_name": "Open Source Community",
      "summary": "Support provided through community involvement.",
      "url": "https://github.com/kaliy/kafka-connect-rss/issues",
      "logo": null
    },
    "owner": {
      "username": "kaliy",
      "type": "User",
      "name": "Artur Kalimullin",
      "url": "https://github.com/kaliy",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/kaliy/kafka-connect-rss/versions/0.1.0/assets/kaliy_logo.jpg"
    },
    "archive": {
      "name": "kaliy-kafka-connect-rss-0.1.0.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/kaliy/kafka-connect-rss/versions/0.1.0/kaliy-kafka-connect-rss-0.1.0.zip",
      "mime_type": "application/zip",
      "md5": "ee0aeef2602f715b44e538773e453b92",
      "sha1": "75ecdbc5a209b6b867ec95e323921b9aa39b049a",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "MIT License",
        "url": "https://opensource.org/licenses/MIT",
        "logo": null
      }
    ],
    "component_types": [
      "source"
    ],
    "release_date": "2019-03-24",
    "tags": [
      "feed",
      "rss",
      "atom"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1553540762000
  },
  {
    "name": "kafka-connect-mongodb",
    "version": "1.3.1",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/hpgrahsl/kafka-connect-mongodb/versions/1.3.1",
    "title": "Kafka Connect MongoDB Sink",
    "description": "It's a basic Apache Kafka Connect SinkConnector which allows moving data from Kafka topics into MongoDB collections.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/hpgrahsl/kafka-connect-mongodb/versions/1.3.1/assets/mongodb-leaf-only.png",
    "documentation_url": "https://github.com/hpgrahsl/kafka-connect-mongodb/blob/master/README.md",
    "source_url": "https://github.com/hpgrahsl/kafka-connect-mongodb/tree/master",
    "support": {
      "provider_name": "Open Source Community",
      "summary": "Support provided through community involvement.",
      "url": "https://github.com/hpgrahsl/kafka-connect-mongodb/issues",
      "logo": null
    },
    "owner": {
      "username": "hpgrahsl",
      "type": null,
      "name": "Hans-Peter Grahsl",
      "url": "https://twitter.com/hpgrahsl",
      "logo": null
    },
    "archive": {
      "name": "hpgrahsl-kafka-connect-mongodb-1.3.1.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/hpgrahsl/kafka-connect-mongodb/versions/1.3.1/hpgrahsl-kafka-connect-mongodb-1.3.1.zip",
      "mime_type": "application/zip",
      "md5": "961d75802d4c6004c2677358e8f0e03a",
      "sha1": "c153b529e4d0fcfb4f275c82e0c136d12ebf13b5",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "The Apache License, Version 2.0",
        "url": "https://www.apache.org/licenses/LICENSE-2.0",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": "2019-04-11",
    "tags": [
      "mongo",
      "giantideas",
      "humongous",
      "documents",
      "json",
      "mongodb",
      "bson",
      "nosql"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1555015727000
  },
  {
    "name": "kafka-connect-simulator",
    "version": "0.1.120",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/jcustenborder/kafka-connect-simulator/versions/0.1.120",
    "title": "Kafka Connect Simulator",
    "description": "A Kafka Connect connector for generating test data.",
    "logo": null,
    "documentation_url": "https://jcustenborder.github.io/kafka-connect-documentation/",
    "source_url": "https://github.com/jcustenborder/kafka-connect-simulator",
    "support": {
      "provider_name": null,
      "summary": "Support provided through community involvement.",
      "url": "https://github.com/jcustenborder/kafka-connect-simulator/issues",
      "logo": null
    },
    "owner": {
      "username": "jcustenborder",
      "type": null,
      "name": "Jeremy Custenborder",
      "url": null,
      "logo": null
    },
    "archive": {
      "name": "jcustenborder-kafka-connect-simulator-0.1.120.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/jcustenborder/kafka-connect-simulator/versions/0.1.120/jcustenborder-kafka-connect-simulator-0.1.120.zip",
      "mime_type": "application/zip",
      "md5": "eebf250d5a2d2835909191f57a276829",
      "sha1": "eb555ba501bc8e742c534d9522b55ee81ded07b5",
      "asc": null
    },
    "docker_image": {
      "namespace": "jcustenborder",
      "name": "kafka-connect-docker",
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Apache License 2.0",
        "url": "https:/github.com/jcustenborder/kafka-connect-simulator/LICENSE",
        "logo": null
      }
    ],
    "component_types": [
      "source",
      "sink"
    ],
    "release_date": "2019-08-15",
    "tags": [
      "Simulator"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1565839858000
  },
  {
    "name": "kafka-connect-redis",
    "version": "0.0.2.7",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/jcustenborder/kafka-connect-redis/versions/0.0.2.7",
    "title": "Kafka Connect Redis",
    "description": "A Kafka Connect connector receiving data from redis.",
    "logo": null,
    "documentation_url": "https://jcustenborder.github.io/kafka-connect-documentation/",
    "source_url": "https://github.com/jcustenborder/kafka-connect-redis",
    "support": {
      "provider_name": null,
      "summary": "Support provided through community involvement.",
      "url": "https://github.com/jcustenborder/kafka-connect-redis/issues",
      "logo": null
    },
    "owner": {
      "username": "jcustenborder",
      "type": null,
      "name": "Jeremy Custenborder",
      "url": null,
      "logo": null
    },
    "archive": {
      "name": "jcustenborder-kafka-connect-redis-0.0.2.7.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/jcustenborder/kafka-connect-redis/versions/0.0.2.7/jcustenborder-kafka-connect-redis-0.0.2.7.zip",
      "mime_type": "application/zip",
      "md5": "f5b07c49b13c320585472c12658ce9de",
      "sha1": "5e0609cce7d84bbe91f1dc838b64e841aa15c146",
      "asc": null
    },
    "docker_image": {
      "namespace": "jcustenborder",
      "name": "kafka-connect-docker",
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "The Apache License, Version 2.0",
        "url": "https://www.apache.org/licenses/LICENSE-2.0",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": "2019-02-13",
    "tags": [
      "Redis"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1550083064000
  },
  {
    "name": "kafka-connect-memcached",
    "version": "0.1.0.10",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/jcustenborder/kafka-connect-memcached/versions/0.1.0.10",
    "title": "Kafka Connect Memcached",
    "description": "A Kafka Connect plugin for writing data to Memcached.",
    "logo": null,
    "documentation_url": "https://jcustenborder.github.io/kafka-connect-documentation/",
    "source_url": "https://github.com/jcustenborder/kafka-connect-memcached",
    "support": {
      "provider_name": null,
      "summary": "Support provided through community involvement.",
      "url": "https://github.com/jcustenborder/kafka-connect-memcached/issues",
      "logo": null
    },
    "owner": {
      "username": "jcustenborder",
      "type": null,
      "name": "Jeremy Custenborder",
      "url": null,
      "logo": null
    },
    "archive": {
      "name": "jcustenborder-kafka-connect-memcached-0.1.0.10.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/jcustenborder/kafka-connect-memcached/versions/0.1.0.10/jcustenborder-kafka-connect-memcached-0.1.0.10.zip",
      "mime_type": "application/zip",
      "md5": "04868a4a08fd27153ec16ebff8642610",
      "sha1": "617d3701bf48e3451d8bddbe0cd9bbd000a568ab",
      "asc": null
    },
    "docker_image": {
      "namespace": "jcustenborder",
      "name": "kafka-connect-docker",
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Apache License 2.0",
        "url": "https://www.apache.org/licenses/LICENSE-2.0.txt",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": "2019-08-14",
    "tags": [
      "cache",
      "Memcache"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1565818654000
  },
  {
    "name": "kafka-connect-twitter",
    "version": "0.3.33",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/jcustenborder/kafka-connect-twitter/versions/0.3.33",
    "title": "Kafka Connect Twitter",
    "description": "Kafka Connect plugin for streaming data from Twitter to Kafka.",
    "logo": null,
    "documentation_url": "https://jcustenborder.github.io/kafka-connect-documentation/",
    "source_url": "https://github.com/jcustenborder/kafka-connect-twitter",
    "support": {
      "provider_name": null,
      "summary": "Support provided through community involvement.",
      "url": "https://github.com/jcustenborder/kafka-connect-twitter/issues",
      "logo": null
    },
    "owner": {
      "username": "jcustenborder",
      "type": null,
      "name": "Jeremy Custenborder",
      "url": null,
      "logo": null
    },
    "archive": {
      "name": "jcustenborder-kafka-connect-twitter-0.3.33.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/jcustenborder/kafka-connect-twitter/versions/0.3.33/jcustenborder-kafka-connect-twitter-0.3.33.zip",
      "mime_type": "application/zip",
      "md5": "67e1be60bd4b167da0a0540684e8318d",
      "sha1": "4562f153e826bba665b4db9060e991199b28792d",
      "asc": null
    },
    "docker_image": {
      "namespace": "jcustenborder",
      "name": "kafka-connect-docker",
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Apache License 2.0",
        "url": "https:/github.com/jcustenborder/kafka-connect-twitter/LICENSE",
        "logo": null
      }
    ],
    "component_types": [
      "source"
    ],
    "release_date": "2019-08-14",
    "tags": [
      "Social",
      "Twitter"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1565817309000
  },
  {
    "name": "kafka-connect-transform-fix",
    "version": "0.1.0.1",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/jcustenborder/kafka-connect-transform-fix/versions/0.1.0.1",
    "title": "Kafka Connect FIX Transformations",
    "description": "Kafka Connect transformation for converting messages that are encoded with the FIX protocol.",
    "logo": null,
    "documentation_url": "https://jcustenborder.github.io/kafka-connect-documentation/",
    "source_url": "https://github.com/jcustenborder/kafka-connect-transform-fix",
    "support": {
      "provider_name": null,
      "summary": "Support provided through community involvement.",
      "url": "https://github.com/jcustenborder/kafka-connect-transform-fix/issues",
      "logo": null
    },
    "owner": {
      "username": "jcustenborder",
      "type": null,
      "name": "Jeremy Custenborder",
      "url": null,
      "logo": null
    },
    "archive": {
      "name": "jcustenborder-kafka-connect-transform-fix-0.1.0.1.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/jcustenborder/kafka-connect-transform-fix/versions/0.1.0.1/jcustenborder-kafka-connect-transform-fix-0.1.0.1.zip",
      "mime_type": "application/zip",
      "md5": "442318384fe8e4795594b49b991a1461",
      "sha1": "71beac37d4e09beab3213932d0415bca680fee83",
      "asc": null
    },
    "docker_image": {
      "namespace": "jcustenborder",
      "name": "kafka-connect-docker",
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Apache License 2.0",
        "url": "https://www.apache.org/licenses/LICENSE-2.0.txt",
        "logo": null
      }
    ],
    "component_types": [
      "transform"
    ],
    "release_date": "2019-03-20",
    "tags": [
      "FIX",
      "Transform"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1553112112000
  },
  {
    "name": "kafka-connect-transform-maxmind",
    "version": "0.1.0.8",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/jcustenborder/kafka-connect-transform-maxmind/versions/0.1.0.8",
    "title": "Kafka Connect Maxmind Transformation",
    "description": "Kafka Connect transformation for adding GeoIP data to Kafka data.",
    "logo": null,
    "documentation_url": "https://jcustenborder.github.io/kafka-connect-documentation/",
    "source_url": "https://github.com/jcustenborder/kafka-connect-transform-maxmind",
    "support": {
      "provider_name": null,
      "summary": "Support provided through community involvement.",
      "url": "https://github.com/jcustenborder/kafka-connect-transform-maxmind/issues",
      "logo": null
    },
    "owner": {
      "username": "jcustenborder",
      "type": null,
      "name": "Jeremy Custenborder",
      "url": null,
      "logo": null
    },
    "archive": {
      "name": "jcustenborder-kafka-connect-transform-maxmind-0.1.0.8.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/jcustenborder/kafka-connect-transform-maxmind/versions/0.1.0.8/jcustenborder-kafka-connect-transform-maxmind-0.1.0.8.zip",
      "mime_type": "application/zip",
      "md5": "c60d676575b18bb092135508c4151788",
      "sha1": "0adb981c1e1bef91b1684e0f5820c959d5984111",
      "asc": null
    },
    "docker_image": {
      "namespace": "jcustenborder",
      "name": "kafka-connect-docker",
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Apache License 2.0",
        "url": "https://www.apache.org/licenses/LICENSE-2.0.txt",
        "logo": null
      }
    ],
    "component_types": [
      "source",
      "sink"
    ],
    "release_date": "2019-08-15",
    "tags": [
      "GeoIP",
      "Transformation",
      "Maxmind"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1565840134000
  },
  {
    "name": "kafka-connect-solr",
    "version": "0.1.28",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/jcustenborder/kafka-connect-solr/versions/0.1.28",
    "title": "Kafka Connect Solr",
    "description": "A Kafka Connect connector copying data from Kafka to Solr.",
    "logo": null,
    "documentation_url": "https://jcustenborder.github.io/kafka-connect-documentation/",
    "source_url": "https://github.com/jcustenborder/kafka-connect-solr",
    "support": {
      "provider_name": null,
      "summary": "Support provided through community involvement.",
      "url": "https://github.com/jcustenborder/kafka-connect-solr/issues",
      "logo": null
    },
    "owner": {
      "username": "jcustenborder",
      "type": null,
      "name": "Jeremy Custenborder",
      "url": null,
      "logo": null
    },
    "archive": {
      "name": "jcustenborder-kafka-connect-solr-0.1.28.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/jcustenborder/kafka-connect-solr/versions/0.1.28/jcustenborder-kafka-connect-solr-0.1.28.zip",
      "mime_type": "application/zip",
      "md5": "976a3b4eaede51688f729c484ace90b3",
      "sha1": "082b9d59cf68c3004be76d2ae6b813c41bffb6cd",
      "asc": null
    },
    "docker_image": {
      "namespace": "jcustenborder",
      "name": "kafka-connect-docker",
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "The Apache License, Version 2.0",
        "url": "https://www.apache.org/licenses/LICENSE-2.0",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": "2019-08-14",
    "tags": [
      "search",
      "Apache Solr"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1565811570000
  },
  {
    "name": "kafka-connect-spooldir",
    "version": "1.0.41",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/jcustenborder/kafka-connect-spooldir/versions/1.0.41",
    "title": "Kafka Connect Spooldir",
    "description": "A Kafka Connect connector reading delimited files from the file system.",
    "logo": null,
    "documentation_url": "https://docs.confluent.io/current/connect/kafka-connect-spooldir/",
    "source_url": "https://github.com/jcustenborder/kafka-connect-spooldir",
    "support": {
      "provider_name": "Confluent, Inc.",
      "summary": "This connector is <a href=\"https://www.confluent.io/subscription/\">supported by Confluent</a> as part of a\n<a href=\"https://www.confluent.io/product/confluent-platform/\">Confluent Platform</a> subscription.",
      "url": "https://docs.confluent.io/current/connect/kafka-connect-spooldir/",
      "logo": null
    },
    "owner": {
      "username": "jcustenborder",
      "type": null,
      "name": "Jeremy Custenborder",
      "url": null,
      "logo": null
    },
    "archive": {
      "name": "jcustenborder-kafka-connect-spooldir-1.0.41.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/jcustenborder/kafka-connect-spooldir/versions/1.0.41/jcustenborder-kafka-connect-spooldir-1.0.41.zip",
      "mime_type": "application/zip",
      "md5": "fd2bfdea2577309f69e88c3348c61951",
      "sha1": "2a7de73d80eae7225c40f950d542feb779d49559",
      "asc": null
    },
    "docker_image": {
      "namespace": "jcustenborder",
      "name": "kafka-connect-docker",
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Apache License 2.0",
        "url": "https:/github.com/jcustenborder/kafka-connect-spooldir/LICENSE",
        "logo": null
      }
    ],
    "component_types": [
      "source"
    ],
    "release_date": "2019-07-11",
    "tags": [
      "csv",
      "json",
      "Flume",
      "File"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1562803665000
  },
  {
    "name": "kafka-connect-transform-common",
    "version": "0.1.0.28",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/jcustenborder/kafka-connect-transform-common/versions/0.1.0.28",
    "title": "Kafka Connect Common Transformations",
    "description": "Common transformations for Kafka Connect.",
    "logo": null,
    "documentation_url": "https://jcustenborder.github.io/kafka-connect-documentation/",
    "source_url": "https://github.com/jcustenborder/kafka-connect-transform-common",
    "support": {
      "provider_name": null,
      "summary": "Support provided through community involvement.",
      "url": "https://github.com/jcustenborder/kafka-connect-transform-common/issues",
      "logo": null
    },
    "owner": {
      "username": "jcustenborder",
      "type": null,
      "name": "Jeremy Custenborder",
      "url": null,
      "logo": null
    },
    "archive": {
      "name": "jcustenborder-kafka-connect-transform-common-0.1.0.28.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/jcustenborder/kafka-connect-transform-common/versions/0.1.0.28/jcustenborder-kafka-connect-transform-common-0.1.0.28.zip",
      "mime_type": "application/zip",
      "md5": "5c1ce5390d1509173428b8a83b1c8d39",
      "sha1": "1baa8a020ceaa93dbc7b49ae8962e351f5440ea6",
      "asc": null
    },
    "docker_image": {
      "namespace": "jcustenborder",
      "name": "kafka-connect-docker",
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Apache License 2.0",
        "url": "https:/github.com/jcustenborder/kafka-connect-transform-common/LICENSE",
        "logo": null
      }
    ],
    "component_types": [
      "source"
    ],
    "release_date": "2019-05-31",
    "tags": [
      "Social",
      "Twitter"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1559337123000
  },
  {
    "name": "kafka-connect-transform-xml",
    "version": "0.1.0.12",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/jcustenborder/kafka-connect-transform-xml/versions/0.1.0.12",
    "title": "Xml Transformation",
    "description": "Kafka Connect transformation for handling Xml data based on a XSD. This transformation will convert text based Xml",
    "logo": null,
    "documentation_url": "https://jcustenborder.github.io/kafka-connect-documentation/",
    "source_url": "https://github.com/jcustenborder/kafka-connect-transform-xml",
    "support": {
      "provider_name": null,
      "summary": "Support provided through community involvement.",
      "url": "https://github.com/jcustenborder/kafka-connect-transform-xml/issues",
      "logo": null
    },
    "owner": {
      "username": "jcustenborder",
      "type": null,
      "name": "Jeremy Custenborder",
      "url": null,
      "logo": null
    },
    "archive": {
      "name": "jcustenborder-kafka-connect-transform-xml-0.1.0.12.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/jcustenborder/kafka-connect-transform-xml/versions/0.1.0.12/jcustenborder-kafka-connect-transform-xml-0.1.0.12.zip",
      "mime_type": "application/zip",
      "md5": "01b4bf297d75eeb2efaba6951bc43f8b",
      "sha1": "716fa42fe62d5bab589d6595c9bac10acec2beff",
      "asc": null
    },
    "docker_image": {
      "namespace": "jcustenborder",
      "name": "kafka-connect-docker",
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Apache License 2.0",
        "url": "https://www.apache.org/licenses/LICENSE-2.0.txt",
        "logo": null
      }
    ],
    "component_types": [
      "transform"
    ],
    "release_date": "2018-10-19",
    "tags": [
      "Xml",
      "Transform"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1539978996000
  },
  {
    "name": "kafka-connect-aws-lambda",
    "version": "1.0-SNAPSHOT",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/llofberg/kafka-connect-aws-lambda/versions/1.0-SNAPSHOT",
    "title": "Kafka Connect AWS Lambda Sink",
    "description": "The AWS Lambda sink connector calls Lambda functions based on events in Kafka topics.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/llofberg/kafka-connect-aws-lambda/versions/1.0-SNAPSHOT/assets/AWS_Lambda_logo.jpg",
    "documentation_url": "https://github.com/llofberg/kafka-connect-aws-lambda/blob/master/README.md",
    "source_url": "https://github.com/llofberg/kafka-connect-aws-lambda",
    "support": null,
    "owner": {
      "username": "llofberg",
      "type": null,
      "name": "Lenny Lofberg",
      "url": "https://github.com/llofberg/",
      "logo": null
    },
    "archive": null,
    "docker_image": null,
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": null,
    "component_types": [
      "sink"
    ],
    "release_date": null,
    "tags": [
      "Cloud",
      "AWS",
      "Lambda"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1535074643000
  },
  {
    "name": "xenon-connector",
    "version": "1.0.0",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/levyx/xenon-connector/versions/1.0.0",
    "title": "Levyx Xenon Connector",
    "description": "Levyx offers a high-performance key value storage engine that enables I/O-intensive legacy and Big Data applications to operate Faster, Simpler, and Cheaper.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/levyx/xenon-connector/versions/1.0.0/assets/Xenon.jpg",
    "documentation_url": "https://github.com/levyx/kafka-xenon",
    "source_url": "https://github.com/levyx/kafka-xenon",
    "support": null,
    "owner": {
      "username": "levyx",
      "type": "Organization",
      "name": "Levyx",
      "url": "https://www.levyx.com/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/levyx/xenon-connector/versions/1.0.0/assets/Xenon.jpg"
    },
    "archive": null,
    "docker_image": null,
    "confluent_verified": {
      "level": "standard"
    },
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": null,
      "confluent_control_center_integration": null,
      "kafka_connect_api": null,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Apache 2.0",
        "url": null,
        "logo": null
      }
    ],
    "component_types": [
      "source"
    ],
    "release_date": null,
    "tags": [
      "Database"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1535074643000
  },
  {
    "name": "kafka-connect-mongodb",
    "version": "0.2",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/mongodb/kafka-connect-mongodb/versions/0.2",
    "title": "MongoDB Connector for Apache Kafka",
    "description": "The official MongoDB Kafka connector, providing both Sink and Source connectors.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/mongodb/kafka-connect-mongodb/versions/0.2/assets/mongodb-leaf.png",
    "documentation_url": "https://github.com/mongodb/mongo-kafka/blob/master/README.md",
    "source_url": "https://github.com/mongodb/mongo-kafka/tree/master",
    "support": {
      "provider_name": "MongoDB",
      "summary": "Officially supported by MongoDB.",
      "url": "http://jira.mongodb.org/browse/KAFKA",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/mongodb/kafka-connect-mongodb/versions/0.2/assets/mongodb-logo.png"
    },
    "owner": {
      "username": "mongodb",
      "type": null,
      "name": "MongoDB",
      "url": "http://www.mongodb.com",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/mongodb/kafka-connect-mongodb/versions/0.2/assets/mongodb-logo.png"
    },
    "archive": {
      "name": "mongodb-kafka-connect-mongodb-0.2.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/mongodb/kafka-connect-mongodb/versions/0.2/mongodb-kafka-connect-mongodb-0.2.zip",
      "mime_type": "application/zip",
      "md5": "eb2dc4ca381b92442c627fb458c53119",
      "sha1": "f3fa4a6e761244715d89600a905f444e72d29d11",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": {
      "level": "gold"
    },
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "The Apache License, Version 2.0",
        "url": "https://www.apache.org/licenses/LICENSE-2.0",
        "logo": null
      }
    ],
    "component_types": [
      "source",
      "sink"
    ],
    "release_date": "2019-07-25",
    "tags": [
      "mongo",
      "analytics",
      "giantideas",
      "humongous",
      "documents",
      "json",
      "mongodb",
      "logs",
      "bson",
      "nosql"
    ],
    "requirements": [
      "MongoDB server for Sink and a MongoDB replicaSet or Sharded replicaSet for Source"
    ],
    "signatures": null,
    "last_modified": 1564429488000
  },
  {
    "name": "kafka-connect-irc",
    "version": "5.0.0",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/cjmatta/kafka-connect-irc/versions/5.0.0",
    "title": "Kafka Connect IRC",
    "description": "A Kafka Connect source connector for Internet Relay Chat",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/cjmatta/kafka-connect-irc/versions/5.0.0/assets/irc-logo.png",
    "documentation_url": "https://github.com/cjmatta/kafka-connect-irc/blob/master/README.md",
    "source_url": null,
    "support": {
      "provider_name": null,
      "summary": null,
      "url": null,
      "logo": null
    },
    "owner": {
      "username": "cjmatta",
      "type": "User",
      "name": "Christopher Matta",
      "url": "https://github.com/cjmatta",
      "logo": null
    },
    "archive": {
      "name": "cjmatta-kafka-connect-irc-5.0.0.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/cjmatta/kafka-connect-irc/versions/5.0.0/cjmatta-kafka-connect-irc-5.0.0.zip",
      "mime_type": "application/zip",
      "md5": "8528b3ce7d97b857253705d0656d1dee",
      "sha1": "6cd32389c5cc1448bffbf748ad1de65486d1ba1d",
      "asc": "-----BEGIN PGP SIGNATURE-----\n\niQEzBAABCAAdFiEE30UApyr11ASqDaFFOdgcJ8+naHMFAlupOsMACgkQOdgcJ8+n\naHPUaQf/ftVKn/HFC8ggOMaC92q1qGyGZ5PTe/bm8W5LRZFY6YfbgAwokBbIZusW\ns11qbQkUfMAZcWk4S8GMGpo82Kw3LegACM02k/mK+/xF/aDPUFZTv3wTJfG2wqJA\nQdvvqqbMk0cJAbNPejuQpYsxlJBQ5OlaXTO8EiakVzFl7QfBxQ9xl/+C00fk4gGh\nfzA4DhnNXvXQ4UO+AWpckrTI/p+wpyTQdA48fF+tdlc9e9QhKJFNIsVqW+aiWgtn\nGPcu73jeU63n48ru+S1qWM6onqgDOYTQs4ZT3Ub7B5D0PdN13judPOxeKnb+HmsB\nsY1lbPIJquurB/mdkh5FNcV2W1BAsg==\n=lUb8\n-----END PGP SIGNATURE-----"
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "The Apache License, Version 2.0",
        "url": "https://www.apache.org/licenses/LICENSE-2.0",
        "logo": null
      }
    ],
    "component_types": [
      "source"
    ],
    "release_date": "2018-09-24",
    "tags": [
      "chat",
      "Internet Relay Chat",
      "IRC"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1537821415000
  },
  {
    "name": "bkatwal-kafka-connect-solr-sink",
    "version": "2.0",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/bkatwal/bkatwal-kafka-connect-solr-sink/versions/2.0",
    "title": "Solr Sink Connector",
    "description": "Consumes plain schemaless JSON data out of Apache Kafka and writes to Apache Solr. Solr must be in <a href=\"https://lucene.apache.org/solr/guide/6_6/solrcloud.html\">SolrCloud mode</a>.",
    "logo": null,
    "documentation_url": "https://github.com/bkatwal/kafka-solr-sink-connector/wiki/Kafka-connect-solr-sink-connector",
    "source_url": "https://github.com/bkatwal/kafka-solr-sink-connector/",
    "support": {
      "provider_name": "Bikas Katwal",
      "summary": "Bikas Katwal provides <a href=\"https://github.com/bkatwal\">full support</a> for this connector",
      "url": "https://github.com/bkatwal",
      "logo": null
    },
    "owner": {
      "username": "bkatwal",
      "type": "User",
      "name": "Bikas Katwal",
      "url": "https://github.com/bkatwal",
      "logo": null
    },
    "archive": {
      "name": "bkatwal-bkatwal-kafka-connect-solr-sink-2.0.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/bkatwal/bkatwal-kafka-connect-solr-sink/versions/2.0/bkatwal-bkatwal-kafka-connect-solr-sink-2.0.zip",
      "mime_type": "application/zip",
      "md5": "b6d9efd9337cae16ea4294d32b4f1e71",
      "sha1": "30b6c300b3ba4a1dc2909b5e54432ce920a26289",
      "asc": null
    },
    "docker_image": null,
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "JSON"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Apache License, Version 2.0",
        "url": "http://www.apache.org/licenses/LICENSE-2.0",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": null,
    "tags": [
      "search",
      "solr"
    ],
    "requirements": [
      "Solr 6.0+"
    ],
    "signatures": null,
    "last_modified": 1546896913000
  },
  {
    "name": "enterprise-extension",
    "version": "4.2",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/hivemq/enterprise-extension/versions/4.2",
    "title": "HiveMQ Enterprise Extension for Kafka",
    "description": "HiveMQ is an enterprise MQTT platform well suited for moving data from IoT devices to the cloud and Kafka.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/hivemq/enterprise-extension/versions/4.2/assets/hivemq-vert.png",
    "documentation_url": "https://www.hivemq.com/docs/4.2/enterprise-extensions/kafka.html",
    "source_url": null,
    "support": {
      "provider_name": "HiveMQ",
      "summary": "This connector is supported by HiveMQ as part of HiveMQ subscription.",
      "url": null,
      "logo": null
    },
    "owner": {
      "username": "hivemq",
      "type": "Organization",
      "name": "HiveMQ",
      "url": "https://www.hivemq.com",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/hivemq/enterprise-extension/versions/4.2/assets/hivemq-vert.png"
    },
    "archive": null,
    "docker_image": null,
    "confluent_verified": {
      "level": "standard"
    },
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": null,
      "confluent_control_center_integration": null,
      "kafka_connect_api": null,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Evaluation Commercial License",
        "url": null,
        "logo": null
      }
    ],
    "component_types": [
      "source"
    ],
    "release_date": null,
    "tags": [
      "MQTT",
      "Internet of Things",
      "IOT"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1567552662000
  },
  {
    "name": "druid-kafka-indexing-service",
    "version": "2.6.1",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/imply/druid-kafka-indexing-service/versions/2.6.1",
    "title": "Druid Kafka indexing service",
    "description": "The Apache Druid (incubating) Kafka indexing service offers exactly-once consumption guarantees from Kafka. The Kafka indexing service is a native Kafka consumer that streams data from Kafka topics and writes to Druid. This service is a part of core Druid and runs natively  as a part of Druid’s ingestion process.  Apache Druid (incubating) is a high-performance analytics data store to store and query large volumes of real-time, complex, event-driven, operational data.  Imply, the original developer of the Kafka indexing service, is the enterprise version of Druid with additional capabilities for data loading, management, security, and visualization.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/imply/druid-kafka-indexing-service/versions/2.6.1/assets/logo.png",
    "documentation_url": "https://docs.imply.io/on-premise/manage-data/ingestion-kafka",
    "source_url": "https://github.com/druid-io/druid/tree/master/extensions-core/kafka-indexing-service",
    "support": {
      "provider_name": null,
      "summary": "Support for the Druid Kafka indexing service for Imply is available from the Imply <a style=\"color:#4597cb\" href=\"https://groups.google.com/forum/#!forum/imply-user-group\">user group</a> or from Imply <a style=\"color:#4597cb\" href=\"https://imply.io/contact\">directly</a>.",
      "url": null,
      "logo": null
    },
    "owner": {
      "username": "imply",
      "type": "Organization",
      "name": "Imply",
      "url": "https://imply.io/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/imply/druid-kafka-indexing-service/versions/2.6.1/assets/logo.png"
    },
    "archive": null,
    "docker_image": null,
    "confluent_verified": {
      "level": "standard"
    },
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": null,
      "confluent_control_center_integration": null,
      "kafka_connect_api": null,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Apache 2.0",
        "url": "https://github.com/druid-io/druid/blob/master/LICENSE",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": null,
    "tags": [
      "Druid",
      "Log",
      "Search",
      "Database",
      "Analytics",
      "Imply"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1535074643000
  },
  {
    "name": "goldengate",
    "version": "12.3.0",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/oracle/goldengate/versions/12.3.0",
    "title": "Oracle GoldenGate",
    "description": "Oracle GoldenGate is a comprehensive software package for real-time data integration and replication in heterogeneous IT environments. The product set enables high availability solutions, real-time data integration, transactional change data capture, data replication, transformations, and verification between operational and analytical enterprise systems. Oracle GoldenGate 12c brings extreme performance with simplified configuration and management, tighter integration with Oracle Database, support for cloud environments, expanded heterogeneity, and enhanced security.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/oracle/goldengate/versions/12.3.0/assets/oracle.jpg",
    "documentation_url": "http://www.oracle.com/technetwork/middleware/goldengate/documentation/index.html",
    "source_url": null,
    "support": null,
    "owner": {
      "username": "oracle",
      "type": "Organization",
      "name": "Oracle",
      "url": "https://www.oracle.com",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/oracle/goldengate/versions/12.3.0/assets/oracle.jpg"
    },
    "archive": null,
    "docker_image": null,
    "confluent_verified": {
      "level": "standard"
    },
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": null,
      "confluent_control_center_integration": null,
      "kafka_connect_api": null,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Proprietary",
        "url": null,
        "logo": null
      }
    ],
    "component_types": [
      "source"
    ],
    "release_date": null,
    "tags": [
      "CDC"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1535074643000
  },
  {
    "name": "sap-hana",
    "version": "1.0.0",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/sap/sap-hana/versions/1.0.0",
    "title": "SAP Hana Connector",
    "description": "Kafka Connect SAP is a set of connectors, using the Apache Kafka Connect framework for reliably connecting Kafka with SAP systems",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/sap/sap-hana/versions/1.0.0/assets/sap-hana-logo.jpg",
    "documentation_url": "https://github.com/SAP/kafka-connect-sap",
    "source_url": "https://github.com/SAP/kafka-connect-sap",
    "support": null,
    "owner": {
      "username": "sap",
      "type": "Organization",
      "name": "SAP",
      "url": "https://www.sap.com/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/sap/sap-hana/versions/1.0.0/assets/sap-hana-logo.jpg"
    },
    "archive": null,
    "docker_image": null,
    "confluent_verified": {
      "level": "standard"
    },
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": null,
      "confluent_control_center_integration": null,
      "kafka_connect_api": null,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Apache 2.0",
        "url": null,
        "logo": null
      }
    ],
    "component_types": [
      "source",
      "sink"
    ],
    "release_date": null,
    "tags": [
      "Database"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1535074643000
  },
  {
    "name": "hvr-cdc",
    "version": "5.3.0",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/hvr/hvr-cdc/versions/5.3.0",
    "title": "HVR Change Data Capture",
    "description": "HVR is the Only Real-Time Data Integration Solution that Provides You the Necessary Replication Capabilities in a Single Unified Environment.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/hvr/hvr-cdc/versions/5.3.0/assets/hvr.png",
    "documentation_url": "https://www.hvr-software.com/wiki/Main_Page",
    "source_url": null,
    "support": null,
    "owner": {
      "username": "hvr",
      "type": "Organization",
      "name": "HVR",
      "url": "https://www.hvr-software.com/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/hvr/hvr-cdc/versions/5.3.0/assets/hvr.jpg"
    },
    "archive": null,
    "docker_image": null,
    "confluent_verified": {
      "level": "standard"
    },
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": null,
      "confluent_control_center_integration": null,
      "kafka_connect_api": null,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Proprietary",
        "url": null,
        "logo": null
      }
    ],
    "component_types": [
      "source"
    ],
    "release_date": null,
    "tags": [
      "CDC"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1556833569000
  },
  {
    "name": "kafka-connect-telegram",
    "version": "0.2.0",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/fbascheper/kafka-connect-telegram/versions/0.2.0",
    "title": "Kafka Connect Telegram",
    "description": "The Telegram connector allows moving data from Kafka to a Telegram chat. It\nwrites data from a topic in Kafka to the configured chat-id.\nIt's possible to send both text, photo and video messages to chats. For complex\nmodels you must use an Avro model, preferably\nin combination with the kafka-connect-avro-converter.",
    "logo": null,
    "documentation_url": "https://github.com/fbascheper/kafka-connect-telegram",
    "source_url": "https://github.com/fbascheper/kafka-connect-telegram",
    "support": {
      "provider_name": null,
      "summary": null,
      "url": null,
      "logo": null
    },
    "owner": {
      "username": "fbascheper",
      "type": "User",
      "name": "Erik-Berndt Scheper.",
      "url": "https://github.com/fbascheper",
      "logo": null
    },
    "archive": {
      "name": "fbascheper-kafka-connect-telegram-0.2.0.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/fbascheper/kafka-connect-telegram/versions/0.2.0/fbascheper-kafka-connect-telegram-0.2.0.zip",
      "mime_type": "application/zip",
      "md5": "3f00fbc7c32e845cd3457d72734d84db",
      "sha1": "44a5ecb8b732afbcaa545f628e974fef7539b68b",
      "asc": "-----BEGIN PGP SIGNATURE-----\n\niQEzBAABCAAdFiEErjt/pkmjD8Yr+C8WcfCIeuOeSDcFAlvsNWEACgkQcfCIeuOe\nSDdCeAgAjWI32Q4gq3kiO4aQB9y7aun20MLaSEZULctw1Fn+KQ/6pJ2Hx0x8Qclp\nAKe5giICtX+HemRiUPOwwcsIlrzmra13aOpjX170KaMLqEsf4wvTK43I2zVYay0F\njRuApzNtNPEIDptqV48QdL6MuCf46u9a6kvKT0OIHO9KV1Ktnozg6soZtSGlGXML\n2r3S+0DFCg/YQUprXJFc/kSnekC/NeUofD1G8TNe8XJhA37Gt9BWzUeKymsw7lB8\nKX07wj7CcunPTfXzC4UOTtBdfFlXshV9rSIhByA753B6b18WWd2MJs4AwSCRIT8U\nKwryOPCbAjS90n80G7xSjS8NrJTF1g==\n=d8Dy\n-----END PGP SIGNATURE-----"
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "The Apache License, Version 2.0",
        "url": "http://www.apache.org/licenses/LICENSE-2.0.txt",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": "2018-11-14",
    "tags": [
      "Telegram",
      "chat"
    ],
    "requirements": [
      "Telegram Bot API"
    ],
    "signatures": null,
    "last_modified": 1542227962000
  },
  {
    "name": "kafka-connect-arangodb",
    "version": "1.0.4",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/jaredpetersen/kafka-connect-arangodb/versions/1.0.4",
    "title": "Kafka Connect ArangoDB",
    "description": "Kafka Connect Sink Connector for ArangoDB",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/jaredpetersen/kafka-connect-arangodb/versions/1.0.4/assets/arangodb-avocado-logo.png",
    "documentation_url": "https://github.com/jaredpetersen/kafka-connect-arangodb/blob/master/README.md",
    "source_url": "https://github.com/jaredpetersen/kafka-connect-arangodb",
    "support": {
      "provider_name": "Open Source Community",
      "summary": "Support provided through community involvement.",
      "url": "https://github.com/jaredpetersen/kafka-connect-arangodb/issues",
      "logo": null
    },
    "owner": {
      "username": "jaredpetersen",
      "type": "User",
      "name": "Jared Petersen",
      "url": "https://github.com/jaredpetersen",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/jaredpetersen/kafka-connect-arangodb/versions/1.0.4/assets/jaredpetersen-logo.png"
    },
    "archive": {
      "name": "jaredpetersen-kafka-connect-arangodb-1.0.4.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/jaredpetersen/kafka-connect-arangodb/versions/1.0.4/jaredpetersen-kafka-connect-arangodb-1.0.4.zip",
      "mime_type": "application/zip",
      "md5": "2b9ff0cf8bbbd06bdeb016af11625b36",
      "sha1": "90924540d4c85ad5c6677d3b20a501c9eba7bca9",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "MIT License",
        "url": "https://opensource.org/licenses/MIT",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": "2019-03-29",
    "tags": [
      "arangodb",
      "json",
      "arango",
      "graph",
      "multimodel",
      "nosql"
    ],
    "requirements": [
      "ArangoDB 3.4+"
    ],
    "signatures": null,
    "last_modified": 1553879359000
  },
  {
    "name": "kafka-connect-bigquery",
    "version": "1.1.2",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/wepay/kafka-connect-bigquery/versions/1.1.2",
    "title": "BigQuery Sink Connector",
    "description": "A sink connector for writing to Google BigQuery, with support for automatic table creation and schema evolution.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/wepay/kafka-connect-bigquery/versions/1.1.2/assets/BigQuery.png",
    "documentation_url": "https://docs.confluent.io/current/connect/kafka-connect-bigquery/",
    "source_url": "https://github.com/wepay/kafka-connect-bigquery",
    "support": {
      "provider_name": "Confluent, Inc.",
      "summary": "Confluent</a> supports WePay's BigQuery connector version 1.1.2 and later, as part of a <a href=\"https://www.confluent.io/product/confluent-platform/\">Confluent Platform</a> subscription.",
      "url": "https://docs.confluent.io/current/connect/kafka-connect-bigquery/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/wepay/kafka-connect-bigquery/versions/1.1.2/assets/confluent.png"
    },
    "owner": {
      "username": "wepay",
      "type": "Organization",
      "name": "WePay",
      "url": "https://go.wepay.com/",
      "logo": null
    },
    "archive": {
      "name": "wepay-kafka-connect-bigquery-1.1.2.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/wepay/kafka-connect-bigquery/versions/1.1.2/wepay-kafka-connect-bigquery-1.1.2.zip",
      "mime_type": "application/zip",
      "md5": "df1612c55a89fcbc0726385c62b24941",
      "sha1": "2d48684333792e2fe694e7ad27b219a667b58aba",
      "asc": null
    },
    "docker_image": null,
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Apache 2.0",
        "url": "https://github.com/wepay/kafka-connect-bigquery/blob/master/LICENSE.md",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": null,
    "tags": [
      "cloud",
      "analytics",
      "data",
      "gcp",
      "google",
      "bigquery",
      "warehouse",
      "platform",
      "nosql"
    ],
    "requirements": [
      "Apache Kafka 0.11 or higher / Confluent Platform 3.3 or higher",
      "Java 1.8 or higher",
      "Active Google Cloud Platform (GCP) account with authorization to create resources",
      "Kafka Connect 0.11 or higher / Confluent Platform 3.3 or higher"
    ],
    "signatures": null,
    "last_modified": 1567206383000
  },
  {
    "name": "kafka-connect-protobuf-converter",
    "version": "2.0.0",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/blueapron/kafka-connect-protobuf-converter/versions/2.0.0",
    "title": "Kafka Connect Protobuf Converter",
    "description": "Proto3 converter for Kafka Connect.",
    "logo": null,
    "documentation_url": "https://github.com/blueapron/kafka-connect-protobuf-converter/blob/master/README.md",
    "source_url": null,
    "support": {
      "provider_name": null,
      "summary": "Support provided through community involvement.",
      "url": "https://github.com/blueapron/kafka-connect-protobuf-converter/issues",
      "logo": null
    },
    "owner": {
      "username": "blueapron",
      "type": "Organization",
      "name": "Blue Apron, LLC.",
      "url": "https://www.blueapron.com/",
      "logo": null
    },
    "archive": {
      "name": "blueapron-kafka-connect-protobuf-converter-2.0.0.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/blueapron/kafka-connect-protobuf-converter/versions/2.0.0/blueapron-kafka-connect-protobuf-converter-2.0.0.zip",
      "mime_type": "application/zip",
      "md5": "84f20ba3bf5e32fb2c9d2cd6957219f5",
      "sha1": "64b5ad03b5cf967eb773f49ac8ca16443f7e9667",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": null,
      "single_message_transforms": false,
      "confluent_control_center_integration": false,
      "kafka_connect_api": false,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "MIT License",
        "url": "http://www.opensource.org/licenses/mit-license.php",
        "logo": null
      }
    ],
    "component_types": [
      "converter"
    ],
    "release_date": "2018-05-23",
    "tags": [
      "protocol buffers",
      "protobuf",
      "proto3",
      "converter"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1535074634000
  },
  {
    "name": "tcvision",
    "version": "6.0.0",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/bossoftware/tcvision/versions/6.0.0",
    "title": "B.O.S. Software tcVISION",
    "description": "<a href=\"https://www.bossoftware.com/index.php/en/products/tcvision-real-time-mainframe-data-integration/\">B.O.S. Software tcVISION</a> is a powerful replication solution that allows for real-time synchronisation including comprehensive data transformation. Kafka is fully supported as an output target including the authentication with Kerberos and the data protection with SSL. The data can be streamed to Kafka as JSON or as AVRO.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/bossoftware/tcvision/versions/6.0.0/assets/logo.png",
    "documentation_url": "https://www.bossoftware.com/index.php/en/tcvision-as-confluent-source-connector",
    "source_url": null,
    "support": {
      "provider_name": "B.O.S. Software",
      "summary": "For more information, go <a style=\"color:#4597cb\" href=\"https://www.bossoftware.de/index.php/en/about-us/contacts/\">here</a>.",
      "url": null,
      "logo": null
    },
    "owner": {
      "username": "bossoftware",
      "type": "Organization",
      "name": "B.O.S. Software ",
      "url": "https://www.bossoftware.de/index.php/en/about-us/contacts/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/bossoftware/tcvision/versions/6.0.0/assets/logo.png"
    },
    "archive": null,
    "docker_image": null,
    "confluent_verified": {
      "level": "standard"
    },
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": null,
      "confluent_control_center_integration": null,
      "kafka_connect_api": null,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Proprietary",
        "url": null,
        "logo": null
      }
    ],
    "component_types": [
      "source"
    ],
    "release_date": null,
    "tags": [
      "CDC"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1548288527000
  },
  {
    "name": "sqdata-connector",
    "version": "3.14.0",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/sqdata/sqdata-connector/versions/3.14.0",
    "title": "SQData CDC Connector",
    "description": "SQData's high-performance mainframe CDC connectors provide near-real-time changed data capture (CDC) and ingestion of complex schemas (IMS, VSAM, DB2, etc.) into Kafka without the need for any source to target field mapping.  Customers select SQData for it's ease of use, utility-like operation, performance and flexible pricing options. More information can be found at www.sqdata.com.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/sqdata/sqdata-connector/versions/3.14.0/assets/sqdata_logo.jpg",
    "documentation_url": "https://portal.sqdata.com/portal/doc.asp",
    "source_url": null,
    "support": {
      "provider_name": "SQData Corporation",
      "summary": "SQData provides full support for this connector. For more information. For more information, see <a style=\"color:#4597cb\" href=\"https://www.sqdata.com\">https://www.sqdata.com</a>.",
      "url": null,
      "logo": null
    },
    "owner": {
      "username": "sqdata",
      "type": "Organization",
      "name": "SQData Corporation",
      "url": "https://www.sqdata.com",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/sqdata/sqdata-connector/versions/3.14.0/assets/sqdata_logo.jpg"
    },
    "archive": null,
    "docker_image": null,
    "confluent_verified": {
      "level": "standard"
    },
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": null,
      "confluent_control_center_integration": null,
      "kafka_connect_api": null,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Proprietary",
        "url": null,
        "logo": null
      }
    ],
    "component_types": [
      "source"
    ],
    "release_date": null,
    "tags": [
      "changed data capture",
      "VSAM",
      "CDC",
      "DB2",
      "Oracle",
      "SQLServer",
      "mainframe"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1556058958000
  },
  {
    "name": "kinetica-connector",
    "version": "6.2.1",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/kinetica/kinetica-connector/versions/6.2.1",
    "title": "Kinetica DB Connector",
    "description": "Kinetica is a distributed, in-memory database accelerated by GPUs that can simultaneously ingest, analyze, and visualize streaming data for truly real-time actionable intelligence.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/kinetica/kinetica-connector/versions/6.2.1/assets/logo-whitewhite-on-indigo_27H.png",
    "documentation_url": "https://github.com/kineticadb/kinetica-connector-kafka",
    "source_url": "https://github.com/kineticadb/kinetica-connector-kafka",
    "support": {
      "provider_name": null,
      "summary": "Support is available from Kinetica directly and issues can be logged <a style=\"color:#4597cb\" href=\"https://github.com/kineticadb/kinetica-connector-kafka/issues\">here</a>.",
      "url": null,
      "logo": null
    },
    "owner": {
      "username": "kinetica",
      "type": "Organization",
      "name": "Kinetica",
      "url": "https://www.kinetica.com/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/kinetica/kinetica-connector/versions/6.2.1/assets/logo-whitewhite-on-indigo_27H.png"
    },
    "archive": null,
    "docker_image": null,
    "confluent_verified": {
      "level": "gold"
    },
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "MIT",
        "url": null,
        "logo": null
      }
    ],
    "component_types": [
      "source",
      "sink"
    ],
    "release_date": null,
    "tags": [
      "Database"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1549557028000
  },
  {
    "name": "push-connector",
    "version": "0.0.1",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/push/push-connector/versions/0.0.1",
    "title": "Push Technology Connector",
    "description": "The Diffusion Kafka Adaptor is a Kafka Connect plugin for transferring data between Diffusion and Kafka. It includes a source connector for publishing real-time Diffusion topic updates to Kafka topics, as well as a sink connector that broadcasts messages from one or more Kafka topics to Diffusion topics. By using Diffusion, Kafka data can be easily published to large numbers of web or mobile clients over the internet at high throughput and low latency. The Diffusion Kafka Adaptor supports primitive values, arrays, maps and structs, as well as dynamic mapping between Diffusion and Kafka topic paths.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/push/push-connector/versions/0.0.1/assets/pushlogo.png",
    "documentation_url": "https://github.com/pushtechnology/diffusion-kafka-connect ",
    "source_url": "https://github.com/pushtechnology/diffusion-kafka-connect",
    "support": null,
    "owner": {
      "username": "push",
      "type": "Organization",
      "name": "Push Technology",
      "url": "https://www.pushtechnology.com/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/push/push-connector/versions/0.0.1/assets/pushlogo.png"
    },
    "archive": null,
    "docker_image": null,
    "confluent_verified": {
      "level": "gold"
    },
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Apache 2.0",
        "url": null,
        "logo": null
      }
    ],
    "component_types": [
      "source",
      "sink"
    ],
    "release_date": null,
    "tags": [
      "Consumer",
      "Diffusion"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1559607175000
  },
  {
    "name": "kafka-connect-neo4j",
    "version": "1.0.2",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/neo4j/kafka-connect-neo4j/versions/1.0.2",
    "title": "Kafka Connect Neo4j Sink",
    "description": "It's a basic Apache Kafka Connect SinkConnector which allows moving data from Kafka topics into Neo4j via Cypher templated queries.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/neo4j/kafka-connect-neo4j/versions/1.0.2/assets/neo4j-logo.png",
    "documentation_url": "https://neo4j-contrib.github.io/neo4j-streams/#_kafka_connect",
    "source_url": "https://github.com/neo4j-contrib/neo4j-streams/tree/master/kafka-connect-neo4j",
    "support": {
      "provider_name": null,
      "summary": "Support through <a href=\"https://neo4j.com/labs/\">Neo4j Labs</a>",
      "url": null,
      "logo": null
    },
    "owner": {
      "username": "neo4j",
      "type": "Organization",
      "name": "Neo4j, Inc.",
      "url": "https://neo4j.com/",
      "logo": null
    },
    "archive": {
      "name": "neo4j-kafka-connect-neo4j-1.0.2.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/neo4j/kafka-connect-neo4j/versions/1.0.2/neo4j-kafka-connect-neo4j-1.0.2.zip",
      "mime_type": "application/zip",
      "md5": "60244571872623c794cea8764e7ebe20",
      "sha1": "bf043fd336a34f7eadf811bbb8c4877033c784c6",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": {
      "level": "gold"
    },
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Apache License, Version 2.0",
        "url": "http://www.apache.org/licenses/LICENSE-2.0.txt",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": "2019-06-17",
    "tags": [
      "relationships",
      "neo4j",
      "nodes",
      "cypher",
      "json",
      "graph",
      "nosql"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1561419712000
  },
  {
    "name": "kafka-connect-shell-source",
    "version": "5.1.0",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/thomaskwscott/kafka-connect-shell-source/versions/5.1.0",
    "title": "Kafka Connect Shell",
    "description": "The Shell source connector allows you to run shell commands and ingest the output into kafka.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/thomaskwscott/kafka-connect-shell-source/versions/5.1.0/assets/shell.png",
    "documentation_url": "https://thomaskwscott.github.io/kafka-connect-shell-source",
    "source_url": "https://github.com/thomaskwscott/kafka-connect-shell-source",
    "support": {
      "provider_name": "Thomas Scott",
      "summary": "Support is provided as best effort only. Please register any issues in the github project.",
      "url": "https://github.com/thomaskwscott/kafka-connect-shell-source/issues",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/thomaskwscott/kafka-connect-shell-source/versions/5.1.0/assets/shell.png"
    },
    "owner": {
      "username": "thomaskwscott",
      "type": "User",
      "name": "Thomas Scott",
      "url": "https://github.com/thomaskwscott",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/thomaskwscott/kafka-connect-shell-source/versions/5.1.0/assets/thomaskwscott.png"
    },
    "archive": {
      "name": "thomaskwscott-kafka-connect-shell-source-5.1.0.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/thomaskwscott/kafka-connect-shell-source/versions/5.1.0/thomaskwscott-kafka-connect-shell-source-5.1.0.zip",
      "mime_type": "application/zip",
      "md5": "3a879587e683c4836d89aa6ec2c4bd23",
      "sha1": "ff44bbe3b3401ff77a4d92415306fd08580342c6",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Apache License 2.0",
        "url": "http://www.apache.org/licenses/LICENSE-2.0.html",
        "logo": null
      }
    ],
    "component_types": [
      "source"
    ],
    "release_date": "2019-02-23",
    "tags": [
      "shell"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1551147761000
  },
  {
    "name": "kafka-connect-shell-sink",
    "version": "5.1.0",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/thomaskwscott/kafka-connect-shell-sink/versions/5.1.0",
    "title": "Kafka Connect Shell",
    "description": "The Shell sink connector allows you to run shell commands triggered and parameterized by messages from Kafka",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/thomaskwscott/kafka-connect-shell-sink/versions/5.1.0/assets/shell.png",
    "documentation_url": "https://thomaskwscott.github.io/kafka-connect-shell-sink",
    "source_url": "https://github.com/thomaskwscott/kafka-connect-shell-sink",
    "support": {
      "provider_name": "Thomas Scott",
      "summary": "Support is provided as best effort only. Please register any issues in the github project.",
      "url": "https://github.com/thomaskwscott/kafka-connect-shell-sink/issues",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/thomaskwscott/kafka-connect-shell-sink/versions/5.1.0/assets/shell.png"
    },
    "owner": {
      "username": "thomaskwscott",
      "type": "User",
      "name": "Thomas Scott",
      "url": "https://github.com/thomaskwscott",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/thomaskwscott/kafka-connect-shell-sink/versions/5.1.0/assets/thomaskwscott.png"
    },
    "archive": {
      "name": "thomaskwscott-kafka-connect-shell-sink-5.1.0.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/thomaskwscott/kafka-connect-shell-sink/versions/5.1.0/thomaskwscott-kafka-connect-shell-sink-5.1.0.zip",
      "mime_type": "application/zip",
      "md5": "faa2b1fc5e763854f752c8ed26c8aed8",
      "sha1": "8d47f04af35b6074079bd569313f8c8174ec4f2a",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Apache License 2.0",
        "url": "http://www.apache.org/licenses/LICENSE-2.0.html",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": "2019-02-23",
    "tags": [
      "shell"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1551147752000
  },
  {
    "name": "kafka-connect-dse",
    "version": "1.1.0",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/datastax/kafka-connect-dse/versions/1.1.0",
    "title": "DataStax Apache Kafka Connector",
    "description": "Built by the team that authors the DataStax Drivers for Apache Cassandra™, the DataStax Apache Kafka™ Connector capitalizes on the best practices of ingesting to DataStax Enterprise (DSE) and DataStax Distribution of Apache Cassandra. \nThis sink connector is built in the Kafka Connect framework and offers a flexible mapping specification that allows to read from many Kafka topics and write to many DataStax tables. \nVisit the DataStax Github repository for examples https://github.com/datastax/kafka-examples",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/datastax/kafka-connect-dse/versions/1.1.0/assets/datastax-logo.png",
    "documentation_url": "https://docs.datastax.com/en/kafka/doc/index.html",
    "source_url": null,
    "support": {
      "provider_name": "DataStax, Inc.",
      "summary": "DataStax provides full support for this connector at https://support.datastax.com and a community slack room #kafka-connector on the DataStax Academy slack https://academy.datastax.com/slack",
      "url": "https://support.datastax.com",
      "logo": null
    },
    "owner": {
      "username": "datastax",
      "type": "Organization",
      "name": "DataStax, Inc.",
      "url": "https://datastax.com/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/datastax/kafka-connect-dse/versions/1.1.0/assets/datastax-logo.png"
    },
    "archive": null,
    "docker_image": null,
    "confluent_verified": {
      "level": "gold"
    },
    "features": {
      "supported_encodings": [
        "all"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": null,
      "kafka_connect_api": true,
      "delivery_guarantee": [
        "at_least_once"
      ]
    },
    "license": [
      {
        "name": "DataStax Apache Kafka Connector License Terms",
        "url": "https://www.datastax.com/terms/datastax-apache-kafka-connector-license-terms",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": null,
    "tags": [
      "analytics",
      "search",
      "database",
      "datastax",
      "cassandra",
      "graph"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1559948282000
  },
  {
    "name": "greenplum-integration",
    "version": "5.13",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/pivotal/greenplum-integration/versions/5.13",
    "title": "Pivotal Greenplum Integration",
    "description": "Pivotal Greenplum Database is a massively parallel processing database server specially designed to manage large scale analytic data warehouses and business intelligence workloads. The Pivotal Greenplum-Kafka Connector provides high speed, parallel data transfer from Apache Kafka to Greenplum Database to support a streaming ETL pipeline.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/pivotal/greenplum-integration/versions/5.13/assets/Pivotal-Greenplum-Logo-FullColor.png",
    "documentation_url": "https://gpdb.docs.pivotal.io/5130/greenplum-kafka/intro.html",
    "source_url": null,
    "support": null,
    "owner": {
      "username": "pivotal",
      "type": "Organization",
      "name": "Pivotal",
      "url": "https://pivotal.io/pivotal-greenplum",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/pivotal/greenplum-integration/versions/5.13/assets/Pivotal-Greenplum-Logo-FullColor.png"
    },
    "archive": null,
    "docker_image": null,
    "confluent_verified": {
      "level": "standard"
    },
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": null,
      "confluent_control_center_integration": null,
      "kafka_connect_api": null,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Proprietary",
        "url": null,
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": null,
    "tags": [
      "Database"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1543566276000
  },
  {
    "name": "data-replication",
    "version": "11.4.0",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/ibm/data-replication/versions/11.4.0",
    "title": "IBM Data Replication",
    "description": "Data replication is a solution that provides trusted data integration and synchronization to enable you to efficiently manage data growth. It empowers your event-driven business by enriching big data systems and mobile applications through the use of real-time information, even capturing data that is constantly changing.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/ibm/data-replication/versions/11.4.0/assets/IBM.jpg",
    "documentation_url": "https://www.ibm.com/support/knowledgecenter/en/SSTRGZ_11.4.0/com.ibm.idr.frontend.doc/pv_welcome.html",
    "source_url": null,
    "support": null,
    "owner": {
      "username": "ibm",
      "type": "Organization",
      "name": "IBM",
      "url": "https://www.ibm.com",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/ibm/data-replication/versions/11.4.0/assets/IBM.jpg"
    },
    "archive": null,
    "docker_image": null,
    "confluent_verified": {
      "level": "standard"
    },
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": null,
      "confluent_control_center_integration": null,
      "kafka_connect_api": null,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Proprietary",
        "url": null,
        "logo": null
      }
    ],
    "component_types": [
      "source"
    ],
    "release_date": null,
    "tags": [
      "CDC"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1535074643000
  },
  {
    "name": "kafka-connect-venafi",
    "version": "0.9.5",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/opencredo/kafka-connect-venafi/versions/0.9.5",
    "title": "Kafka Connect Venafi",
    "description": "This connector connects via HTTP to your instance of the Venafi Platform and pulls\nyour Log events into Kafka, allowing you to do any filtering/transforming/processing\nyou'd like to do within a comfortable Kafka environment.\n\nN.B. Currently the connector starts from the beginning of time (i.e. processes all past\nevents first), a future release will allow the option of starting from now (i.e.\nskipping all previous events).",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/opencredo/kafka-connect-venafi/versions/0.9.5/assets/venafi.png",
    "documentation_url": "https://github.com/opencredo/kafka-connect-venafi/blob/master/README.md",
    "source_url": "https://github.com/opencredo/kafka-connect-venafi.git",
    "support": {
      "provider_name": "OpenCredo Ltd.",
      "summary": "OpenCredo supports the Venafi source connector on behalf of Venafi.",
      "url": "https://github.com/opencredo/kafka-connect-venafi",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/opencredo/kafka-connect-venafi/versions/0.9.5/assets/opencredo.png"
    },
    "owner": {
      "username": "opencredo",
      "type": "Organization",
      "name": "OpenCredo Ltd.",
      "url": "https://opencredo.com/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/opencredo/kafka-connect-venafi/versions/0.9.5/assets/opencredo.png"
    },
    "archive": {
      "name": "opencredo-kafka-connect-venafi-0.9.5.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/opencredo/kafka-connect-venafi/versions/0.9.5/opencredo-kafka-connect-venafi-0.9.5.zip",
      "mime_type": "application/zip",
      "md5": "5bbaaa530bdb9afecb3dec6fe17de84e",
      "sha1": "aadb804146c691ba6d6e30771de9685dc1652ee2",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": {
      "level": "gold"
    },
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Apache License 2.0",
        "url": "https://www.apache.org/licenses/LICENSE-2.0",
        "logo": null
      }
    ],
    "component_types": [
      "source"
    ],
    "release_date": "2019-03-12",
    "tags": [
      "venafi"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1553539549000
  },
  {
    "name": "ignite-connector",
    "version": "8.7.5",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/gridgain/ignite-connector/versions/8.7.5",
    "title": "Ignite Connector",
    "description": "kafka-connect-gridgain is a Kafka Connect plugin for transferring data between GridGain cluster and Kafka. It includes a Source connector for publishing GridGain caches updates to Kafka topics, as well as a Sink connector that subscribes to one or more Kafka topics and writes the messages to GridGain caches.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/gridgain/ignite-connector/versions/8.7.5/assets/gridgain-logo.png",
    "documentation_url": "https://docs.gridgain.com/docs",
    "source_url": null,
    "support": null,
    "owner": {
      "username": "gridgain",
      "type": "Organization",
      "name": "GridGain",
      "url": "https://www.gridgain.com/",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/gridgain/ignite-connector/versions/8.7.5/assets/gridgain-logo.png"
    },
    "archive": null,
    "docker_image": null,
    "confluent_verified": {
      "level": "gold"
    },
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Proprietary",
        "url": null,
        "logo": null
      }
    ],
    "component_types": [
      "source",
      "sink"
    ],
    "release_date": null,
    "tags": [
      "Database",
      "In-memory"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1559261169000
  },
  {
    "name": "kafka-connect-splunk",
    "version": "1.1.1",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/splunk/kafka-connect-splunk/versions/1.1.1",
    "title": "Splunk Sink Connector",
    "description": "A sink connector for writing Apache Kafka records to Splunk via Splunk HTTP Event Collector(HEC). The connector supports in-flight data transformation and enrichment.- High scalability, allowing linear scaling, limited only by the hardware supplied to the Kafka Connect environment, high reliability via at-least-once delivery, and support for ingestion of Kafka Record headers. <p>Requires: <ul><li>Broker: Apache Kafka 1.0.0 or above, or Confluent Platform 4.0.0 or above</li><li>Kafka Connect: Apache Kafka 1.1.0 or above, or Confluent Platform 4.1.0</li><li>Java 1.8 or above</li><li>Splunk environment of version 6.5 or above, configured with valid HTTP Event Collector (HEC) tokens</li></ul>",
    "logo": null,
    "documentation_url": "https://docs.confluent.io/current/connect/kafka-connect-splunk/",
    "source_url": "https://github.com/splunk/kafka-connect-splunk",
    "support": {
      "provider_name": "Confluent, Inc.",
      "summary": "Confluent</a> supports Splunk Sink connector version 1.1.1 and later, as part of a <a href=\"https://www.confluent.io/product/confluent-platform/\">Confluent Platform</a> subscription.",
      "url": "https://docs.confluent.io/current/connect/kafka-connect-splunk",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/splunk/kafka-connect-splunk/versions/1.1.1/assets/confluent.png"
    },
    "owner": {
      "username": "splunk",
      "type": "Organization",
      "name": "Splunk",
      "url": "https://splunkbase.splunk.com/",
      "logo": null
    },
    "archive": {
      "name": "splunk-kafka-connect-splunk-1.1.1.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/splunk/kafka-connect-splunk/versions/1.1.1/splunk-kafka-connect-splunk-1.1.1.zip",
      "mime_type": "application/zip",
      "md5": "d6aefe86fbedde1e6ff0df09b4d9eaa4",
      "sha1": "b9b72fb49d2e932e7d18dab4f697c0c9e005b783",
      "asc": null
    },
    "docker_image": null,
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Apache 2.0",
        "url": "https://github.com/splunk/kafka-connect-splunk/blob/master/LICENSE",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": null,
    "tags": [
      "logfile",
      "hec",
      "splunk",
      "log capture",
      "monitoring",
      "logs",
      "http event collector"
    ],
    "requirements": [
      "Kafka Connect 1.1+ / Confluent Platform 4.1+",
      "Splunk 6.5+",
      "Java 1.8+",
      "Apache Kafka 1.0+ / Confluent Platform 4.0+"
    ],
    "signatures": null,
    "last_modified": 1567206277000
  },
  {
    "name": "kafka-connect-phoenix",
    "version": "0.1",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/dhananjaypatkar/kafka-connect-phoenix/versions/0.1",
    "title": "Kafka Connect Phoenix",
    "description": "Kafka connect Sink Connector for Apache Phoenix [SQL layer on top of HBase]",
    "logo": null,
    "documentation_url": "https://github.com/dhananjaypatkar/kafka-connect-phoenix/wiki/Kafka-Connect-Phoenix",
    "source_url": "https://github.com/dhananjaypatkar/kafka-connect-phoenix",
    "support": {
      "provider_name": null,
      "summary": null,
      "url": null,
      "logo": null
    },
    "owner": {
      "username": "dhananjaypatkar",
      "type": "User",
      "name": "Dhananjay Patkar",
      "url": null,
      "logo": null
    },
    "archive": {
      "name": "dhananjaypatkar-kafka-connect-phoenix-0.1.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/dhananjaypatkar/kafka-connect-phoenix/versions/0.1/dhananjaypatkar-kafka-connect-phoenix-0.1.zip",
      "mime_type": "application/zip",
      "md5": "ca227c9d044ccd7f3135376d32d3ccce",
      "sha1": "34023c5dc2977ea769f1f9ecd9201080b3605e4e",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "JSON"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": false,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Apache License, Version 2.0",
        "url": "https://www.apache.org/licenses/LICENSE-2.0.txt",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": "2018-07-24",
    "tags": [
      "Kafka Connect Sink",
      "Big Data",
      "Phoenix",
      "Apache",
      "HBase"
    ],
    "requirements": [
      "Apache Phoenix 4.7+"
    ],
    "signatures": null,
    "last_modified": 1535074643000
  },
  {
    "name": "kafka-connect-log-analytics",
    "version": "0.1",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/chaitalisagesh/kafka-connect-log-analytics/versions/0.1",
    "title": "Kafka Connect Log Analytics",
    "description": "Kafka connect Sink Connector for Microsoft Log\nAnalytics",
    "logo": null,
    "documentation_url": "https://github.com/chaitalisagesh/kafka-connect-log-analytics/wiki/kafka-connect-log-analytics",
    "source_url": "https://github.com/chaitalisagesh/kafka-connect-log-analytics",
    "support": {
      "provider_name": null,
      "summary": null,
      "url": null,
      "logo": null
    },
    "owner": {
      "username": "chaitalisagesh",
      "type": "User",
      "name": "Chaitali Sagesh Chullikattil",
      "url": null,
      "logo": null
    },
    "archive": {
      "name": "chaitalisagesh-kafka-connect-log-analytics-0.1.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/chaitalisagesh/kafka-connect-log-analytics/versions/0.1/chaitalisagesh-kafka-connect-log-analytics-0.1.zip",
      "mime_type": "application/zip",
      "md5": "25765ee4a32146f79d6033ab97760727",
      "sha1": "211d713f82648ce578efecb63b5c15b845a104b2",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "json"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": false,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "Apache License, Version 2.0",
        "url": "https://www.apache.org/licenses/LICENSE-2.0.txt",
        "logo": null
      }
    ],
    "component_types": [
      "sink"
    ],
    "release_date": "2019-08-29",
    "tags": [
      "Big Data",
      "Microsoft",
      "Log Analytics"
    ],
    "requirements": [
      "Log analytics workspace"
    ],
    "signatures": null,
    "last_modified": 1567195961000
  },
  {
    "name": "kafka-connect-reddit",
    "version": "0.1.2",
    "manifest_url": "https://api.hub.confluent.io/api/plugins/C0urante/kafka-connect-reddit/versions/0.1.2",
    "title": "Kafka Connect Reddit",
    "description": "The source connector consumes posts and comments from Reddit in real time. It's\npossible to read comments from one collection of subreddits and posts from a different\ncollection, and <a href=\"https://www.reddit.com/r/all/\">r/all</a> can be read from for\neither.\n\nSeparate topics are used for posts and comments; they default to reddit-posts and\nreddit-comments respectively but can be configured differently if necessary.\n\n<a href=\"https://github.com/mattbdean/jraw\">JRAW</a> is used to continuously stream new\nposts and comments; many thanks go to\n<a href=\"https://github.com/mattbdean\">Matt Dean</a> for creating that excellent\nlibrary.\n\nThis connector is currently intended for development and entertainment purposes only and\nis not recommended or endorsed for production use cases.",
    "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/C0urante/kafka-connect-reddit/versions/0.1.2/assets/reddit.png",
    "documentation_url": "https://github.com/C0urante/kafka-connect-reddit",
    "source_url": "https://github.com/C0urante/kafka-connect-reddit",
    "support": {
      "provider_name": "Open Source Community",
      "summary": "This is an open-source project supported and maintained on a best-effort by the\ncommunity and its creator.",
      "url": "https://github.com/C0urante/kafka-connect-reddit/issues",
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/C0urante/kafka-connect-reddit/versions/0.1.2/assets/github.png"
    },
    "owner": {
      "username": "C0urante",
      "type": "User",
      "name": "Chris Egerton",
      "url": null,
      "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/C0urante/kafka-connect-reddit/versions/0.1.2/assets/aku.jpeg"
    },
    "archive": {
      "name": "C0urante-kafka-connect-reddit-0.1.2.zip",
      "url": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/C0urante/kafka-connect-reddit/versions/0.1.2/C0urante-kafka-connect-reddit-0.1.2.zip",
      "mime_type": "application/zip",
      "md5": "461cd2ebc2249ad98e3519ec9318f398",
      "sha1": "b06a6c0994fb230609444fcf973f9148f6fdb0e1",
      "asc": null
    },
    "docker_image": {
      "namespace": null,
      "name": null,
      "tag": null,
      "registry": null
    },
    "confluent_verified": null,
    "features": {
      "supported_encodings": [
        "any"
      ],
      "single_message_transforms": true,
      "confluent_control_center_integration": true,
      "kafka_connect_api": true,
      "delivery_guarantee": null
    },
    "license": [
      {
        "name": "DWTFPL Version 2",
        "url": "http://www.wtfpl.net/txt/copying/",
        "logo": "https://d1i4a15mxbxib1.cloudfront.net/api/plugins/C0urante/kafka-connect-reddit/versions/0.1.2/assets/wtfpl.png"
      }
    ],
    "component_types": [
      "source"
    ],
    "release_date": "2019-06-18",
    "tags": [
      "stream",
      "social",
      "reddit",
      "live",
      "jraw",
      "network"
    ],
    "requirements": null,
    "signatures": null,
    "last_modified": 1560881569000
  }
]